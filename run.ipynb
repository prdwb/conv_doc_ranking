{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertTokenizer)\n",
    "from modeling import BertConcatForStatefulSearch, HierBertConcatForStatefulSearch\n",
    "\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "from utils import (compute_metrics, convert_examples_to_features, output_modes, ConcatModelDataset)\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertConcatForStatefulSearch, BertTokenizer),\n",
    "    'hier': (BertConfig, HierBertConcatForStatefulSearch, BertTokenizer)\n",
    "}\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        \n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_dataset, eval_dataset, model, tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter(os.path.join(args.output_dir, 'logs'))\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, \n",
    "                                  batch_size=args.train_batch_size, num_workers=args.num_workers)\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                          output_device=args.local_rank,\n",
    "                                                          find_unused_parameters=True)\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "                   args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    best_eval_mrr = 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
    "    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            guids = batch['guid']\n",
    "            batch = {k: v.to(args.device) for k, v in batch.items() if k != 'guid'}\n",
    "            inputs = {'input_ids':      batch['input_ids'],\n",
    "                      'attention_mask': batch['input_mask'],\n",
    "                      'token_type_ids': batch['segment_ids'],\n",
    "                      'labels':         batch['ranker_label_ids']}\n",
    "            if args.model_type == 'hier':\n",
    "                inputs['hier_mask'] = batch['hier_mask']\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics                   \n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    # Save model checkpoint if it outperforms previous models\n",
    "                    # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                    if args.local_rank == -1 and args.evaluate_during_training:\n",
    "                        results, eval_output = evaluate(args, eval_dataset, model, \n",
    "                                                        tokenizer, args.per_gpu_eval_batch_size)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    \n",
    "                    if results['mrr'] > best_eval_mrr:\n",
    "                        best_eval_mrr = results['mrr']\n",
    "                        output_dir = os.path.join(args.output_dir, 'checkpoint')\n",
    "                        if not os.path.exists(output_dir):\n",
    "                            os.makedirs(output_dir)\n",
    "                        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                        model_to_save.save_pretrained(output_dir)\n",
    "                        torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "                        logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "                        \n",
    "                        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "                        with open(output_eval_file, \"w\") as writer:\n",
    "                            logger.info(\"***** Best eval results so far *****\")\n",
    "                            for key in sorted(results.keys()):\n",
    "                                logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "                                writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "                                \n",
    "                        output_eval_preds_file = os.path.join(args.output_dir, \"eval_preds.txt\")\n",
    "                        with open(output_eval_preds_file, 'w') as writer:\n",
    "                            json.dump(eval_output, writer)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, eval_dataset, model, tokenizer, batch_size, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_task = args.task_name\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    results = {}\n",
    "    # eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)\n",
    "\n",
    "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "    args.eval_batch_size = batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, \n",
    "                                 batch_size=args.eval_batch_size, num_workers=args.num_workers)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    all_eval_guids = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        eval_guids = batch['guid']\n",
    "        all_eval_guids.extend(eval_guids)\n",
    "        # batch = tuple(t.to(args.device) for t in batch)\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items() if k != 'guid'}\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch['input_ids'],\n",
    "                      'attention_mask': batch['input_mask'],\n",
    "                      'token_type_ids': batch['segment_ids'],\n",
    "                      'labels':         batch['ranker_label_ids']}\n",
    "            if args.model_type == 'hier':\n",
    "                inputs['hier_mask'] = batch['hier_mask']\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args.output_mode == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args.output_mode == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    elif args.output_mode == \"ranking\":\n",
    "        preds = softmax(preds, axis=1)\n",
    "        preds = np.squeeze(preds[:, 1])    \n",
    "\n",
    "    result, qrels, run = compute_metrics(eval_task, preds, out_label_ids, guids=all_eval_guids)\n",
    "    results.update(result)\n",
    "    eval_output = {'qrels': qrels,\n",
    "                  'run': run,\n",
    "                  'ranker_test_all_label_ids': out_label_ids.tolist(),\n",
    "                  'guids': all_eval_guids,\n",
    "                  'preds': preds.tolist()}\n",
    "\n",
    "    # output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "    # with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "        # writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results, eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/10/2019 22:14:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.modeling_utils -   loading configuration file /mnt/scratch/chenqu/huggingface/config.json\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"stateful_search\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/huggingface/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/mnt/scratch/chenqu/huggingface/' is a path or url to a directory containing tokenizer files.\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /mnt/scratch/chenqu/huggingface/added_tokens.json. We won't load it.\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /mnt/scratch/chenqu/huggingface/special_tokens_map.json. We won't load it.\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /mnt/scratch/chenqu/huggingface/tokenizer_config.json. We won't load it.\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/huggingface/vocab.txt\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   Adding [EMPTY_QUERY] to the vocabulary\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.tokenization_utils -   Adding [EMPTY_TITLE] to the vocabulary\n",
      "09/10/2019 22:14:43 - INFO - pytorch_transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/huggingface/pytorch_model.bin\n",
      "09/10/2019 22:14:50 - INFO - pytorch_transformers.modeling_utils -   Weights of HierBertConcatForStatefulSearch not initialized from pretrained model: ['bert.encoder.layer.0.hier.att.attention.self.query.weight', 'bert.encoder.layer.0.hier.att.attention.self.query.bias', 'bert.encoder.layer.0.hier.att.attention.self.key.weight', 'bert.encoder.layer.0.hier.att.attention.self.key.bias', 'bert.encoder.layer.0.hier.att.attention.self.value.weight', 'bert.encoder.layer.0.hier.att.attention.self.value.bias', 'bert.encoder.layer.0.hier.att.attention.output.dense.weight', 'bert.encoder.layer.0.hier.att.attention.output.dense.bias', 'bert.encoder.layer.0.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.hier.att.intermediate.dense.weight', 'bert.encoder.layer.0.hier.att.intermediate.dense.bias', 'bert.encoder.layer.0.hier.att.output.dense.weight', 'bert.encoder.layer.0.hier.att.output.dense.bias', 'bert.encoder.layer.0.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.0.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.1.hier.att.attention.self.query.weight', 'bert.encoder.layer.1.hier.att.attention.self.query.bias', 'bert.encoder.layer.1.hier.att.attention.self.key.weight', 'bert.encoder.layer.1.hier.att.attention.self.key.bias', 'bert.encoder.layer.1.hier.att.attention.self.value.weight', 'bert.encoder.layer.1.hier.att.attention.self.value.bias', 'bert.encoder.layer.1.hier.att.attention.output.dense.weight', 'bert.encoder.layer.1.hier.att.attention.output.dense.bias', 'bert.encoder.layer.1.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.hier.att.intermediate.dense.weight', 'bert.encoder.layer.1.hier.att.intermediate.dense.bias', 'bert.encoder.layer.1.hier.att.output.dense.weight', 'bert.encoder.layer.1.hier.att.output.dense.bias', 'bert.encoder.layer.1.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.1.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.2.hier.att.attention.self.query.weight', 'bert.encoder.layer.2.hier.att.attention.self.query.bias', 'bert.encoder.layer.2.hier.att.attention.self.key.weight', 'bert.encoder.layer.2.hier.att.attention.self.key.bias', 'bert.encoder.layer.2.hier.att.attention.self.value.weight', 'bert.encoder.layer.2.hier.att.attention.self.value.bias', 'bert.encoder.layer.2.hier.att.attention.output.dense.weight', 'bert.encoder.layer.2.hier.att.attention.output.dense.bias', 'bert.encoder.layer.2.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.hier.att.intermediate.dense.weight', 'bert.encoder.layer.2.hier.att.intermediate.dense.bias', 'bert.encoder.layer.2.hier.att.output.dense.weight', 'bert.encoder.layer.2.hier.att.output.dense.bias', 'bert.encoder.layer.2.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.2.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.3.hier.att.attention.self.query.weight', 'bert.encoder.layer.3.hier.att.attention.self.query.bias', 'bert.encoder.layer.3.hier.att.attention.self.key.weight', 'bert.encoder.layer.3.hier.att.attention.self.key.bias', 'bert.encoder.layer.3.hier.att.attention.self.value.weight', 'bert.encoder.layer.3.hier.att.attention.self.value.bias', 'bert.encoder.layer.3.hier.att.attention.output.dense.weight', 'bert.encoder.layer.3.hier.att.attention.output.dense.bias', 'bert.encoder.layer.3.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.hier.att.intermediate.dense.weight', 'bert.encoder.layer.3.hier.att.intermediate.dense.bias', 'bert.encoder.layer.3.hier.att.output.dense.weight', 'bert.encoder.layer.3.hier.att.output.dense.bias', 'bert.encoder.layer.3.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.3.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.4.hier.att.attention.self.query.weight', 'bert.encoder.layer.4.hier.att.attention.self.query.bias', 'bert.encoder.layer.4.hier.att.attention.self.key.weight', 'bert.encoder.layer.4.hier.att.attention.self.key.bias', 'bert.encoder.layer.4.hier.att.attention.self.value.weight', 'bert.encoder.layer.4.hier.att.attention.self.value.bias', 'bert.encoder.layer.4.hier.att.attention.output.dense.weight', 'bert.encoder.layer.4.hier.att.attention.output.dense.bias', 'bert.encoder.layer.4.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.hier.att.intermediate.dense.weight', 'bert.encoder.layer.4.hier.att.intermediate.dense.bias', 'bert.encoder.layer.4.hier.att.output.dense.weight', 'bert.encoder.layer.4.hier.att.output.dense.bias', 'bert.encoder.layer.4.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.4.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.5.hier.att.attention.self.query.weight', 'bert.encoder.layer.5.hier.att.attention.self.query.bias', 'bert.encoder.layer.5.hier.att.attention.self.key.weight', 'bert.encoder.layer.5.hier.att.attention.self.key.bias', 'bert.encoder.layer.5.hier.att.attention.self.value.weight', 'bert.encoder.layer.5.hier.att.attention.self.value.bias', 'bert.encoder.layer.5.hier.att.attention.output.dense.weight', 'bert.encoder.layer.5.hier.att.attention.output.dense.bias', 'bert.encoder.layer.5.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.hier.att.intermediate.dense.weight', 'bert.encoder.layer.5.hier.att.intermediate.dense.bias', 'bert.encoder.layer.5.hier.att.output.dense.weight', 'bert.encoder.layer.5.hier.att.output.dense.bias', 'bert.encoder.layer.5.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.5.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.6.hier.att.attention.self.query.weight', 'bert.encoder.layer.6.hier.att.attention.self.query.bias', 'bert.encoder.layer.6.hier.att.attention.self.key.weight', 'bert.encoder.layer.6.hier.att.attention.self.key.bias', 'bert.encoder.layer.6.hier.att.attention.self.value.weight', 'bert.encoder.layer.6.hier.att.attention.self.value.bias', 'bert.encoder.layer.6.hier.att.attention.output.dense.weight', 'bert.encoder.layer.6.hier.att.attention.output.dense.bias', 'bert.encoder.layer.6.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.hier.att.intermediate.dense.weight', 'bert.encoder.layer.6.hier.att.intermediate.dense.bias', 'bert.encoder.layer.6.hier.att.output.dense.weight', 'bert.encoder.layer.6.hier.att.output.dense.bias', 'bert.encoder.layer.6.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.6.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.7.hier.att.attention.self.query.weight', 'bert.encoder.layer.7.hier.att.attention.self.query.bias', 'bert.encoder.layer.7.hier.att.attention.self.key.weight', 'bert.encoder.layer.7.hier.att.attention.self.key.bias', 'bert.encoder.layer.7.hier.att.attention.self.value.weight', 'bert.encoder.layer.7.hier.att.attention.self.value.bias', 'bert.encoder.layer.7.hier.att.attention.output.dense.weight', 'bert.encoder.layer.7.hier.att.attention.output.dense.bias', 'bert.encoder.layer.7.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.hier.att.intermediate.dense.weight', 'bert.encoder.layer.7.hier.att.intermediate.dense.bias', 'bert.encoder.layer.7.hier.att.output.dense.weight', 'bert.encoder.layer.7.hier.att.output.dense.bias', 'bert.encoder.layer.7.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.7.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.8.hier.att.attention.self.query.weight', 'bert.encoder.layer.8.hier.att.attention.self.query.bias', 'bert.encoder.layer.8.hier.att.attention.self.key.weight', 'bert.encoder.layer.8.hier.att.attention.self.key.bias', 'bert.encoder.layer.8.hier.att.attention.self.value.weight', 'bert.encoder.layer.8.hier.att.attention.self.value.bias', 'bert.encoder.layer.8.hier.att.attention.output.dense.weight', 'bert.encoder.layer.8.hier.att.attention.output.dense.bias', 'bert.encoder.layer.8.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.hier.att.intermediate.dense.weight', 'bert.encoder.layer.8.hier.att.intermediate.dense.bias', 'bert.encoder.layer.8.hier.att.output.dense.weight', 'bert.encoder.layer.8.hier.att.output.dense.bias', 'bert.encoder.layer.8.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.8.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.9.hier.att.attention.self.query.weight', 'bert.encoder.layer.9.hier.att.attention.self.query.bias', 'bert.encoder.layer.9.hier.att.attention.self.key.weight', 'bert.encoder.layer.9.hier.att.attention.self.key.bias', 'bert.encoder.layer.9.hier.att.attention.self.value.weight', 'bert.encoder.layer.9.hier.att.attention.self.value.bias', 'bert.encoder.layer.9.hier.att.attention.output.dense.weight', 'bert.encoder.layer.9.hier.att.attention.output.dense.bias', 'bert.encoder.layer.9.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.hier.att.intermediate.dense.weight', 'bert.encoder.layer.9.hier.att.intermediate.dense.bias', 'bert.encoder.layer.9.hier.att.output.dense.weight', 'bert.encoder.layer.9.hier.att.output.dense.bias', 'bert.encoder.layer.9.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.9.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.10.hier.att.attention.self.query.weight', 'bert.encoder.layer.10.hier.att.attention.self.query.bias', 'bert.encoder.layer.10.hier.att.attention.self.key.weight', 'bert.encoder.layer.10.hier.att.attention.self.key.bias', 'bert.encoder.layer.10.hier.att.attention.self.value.weight', 'bert.encoder.layer.10.hier.att.attention.self.value.bias', 'bert.encoder.layer.10.hier.att.attention.output.dense.weight', 'bert.encoder.layer.10.hier.att.attention.output.dense.bias', 'bert.encoder.layer.10.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.hier.att.intermediate.dense.weight', 'bert.encoder.layer.10.hier.att.intermediate.dense.bias', 'bert.encoder.layer.10.hier.att.output.dense.weight', 'bert.encoder.layer.10.hier.att.output.dense.bias', 'bert.encoder.layer.10.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.10.hier.att.output.LayerNorm.bias', 'bert.encoder.layer.11.hier.att.attention.self.query.weight', 'bert.encoder.layer.11.hier.att.attention.self.query.bias', 'bert.encoder.layer.11.hier.att.attention.self.key.weight', 'bert.encoder.layer.11.hier.att.attention.self.key.bias', 'bert.encoder.layer.11.hier.att.attention.self.value.weight', 'bert.encoder.layer.11.hier.att.attention.self.value.bias', 'bert.encoder.layer.11.hier.att.attention.output.dense.weight', 'bert.encoder.layer.11.hier.att.attention.output.dense.bias', 'bert.encoder.layer.11.hier.att.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.hier.att.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.hier.att.intermediate.dense.weight', 'bert.encoder.layer.11.hier.att.intermediate.dense.bias', 'bert.encoder.layer.11.hier.att.output.dense.weight', 'bert.encoder.layer.11.hier.att.output.dense.bias', 'bert.encoder.layer.11.hier.att.output.LayerNorm.weight', 'bert.encoder.layer.11.hier.att.output.LayerNorm.bias', 'classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/10/2019 22:14:50 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in HierBertConcatForStatefulSearch: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "09/10/2019 22:14:54 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/mnt/scratch/chenqu/aol/preprocessed/', dataset='aol', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, enable_component_embeddings=True, enable_turn_id_embeddings=True, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, history_num=2, include_skipped=True, learning_rate=3e-05, load_small=False, local_rank=-1, logging_steps=5, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='/mnt/scratch/chenqu/huggingface/', model_type='hier', n_gpu=1, no_cuda=False, num_train_epochs=3.0, num_workers=2, output_dir='/mnt/scratch/chenqu/stateful_search/20000/', output_mode='ranking', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=2, per_gpu_test_batch_size=2, per_gpu_train_batch_size=4, save_steps=5000, seed=42, server_ip='', server_port='', task_name='stateful_search', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "09/10/2019 22:14:54 - INFO - utils -   processing aol data\n",
      "09/10/2019 22:14:56 - INFO - utils -   processing aol data\n",
      "09/10/2019 22:14:56 - INFO - utils -   processing aol data\n",
      "09/10/2019 22:14:59 - INFO - __main__ -   ***** Running training *****\n",
      "09/10/2019 22:14:59 - INFO - __main__ -     Num examples = 2834835\n",
      "09/10/2019 22:14:59 - INFO - __main__ -     Num Epochs = 3\n",
      "09/10/2019 22:14:59 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
      "09/10/2019 22:14:59 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "09/10/2019 22:14:59 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "09/10/2019 22:14:59 - INFO - __main__ -     Total optimization steps = 2126127\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/708709 [00:00<?, ?it/s]\u001b[A/net/home/chenqu/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "\n",
      "Iteration:   0%|          | 1/708709 [00:03<726:15:24,  3.69s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/708709 [00:04<560:14:47,  2.85s/it]\u001b[A\n",
      "Iteration:   0%|          | 3/708709 [00:05<441:19:16,  2.24s/it]\u001b[A\n",
      "Iteration:   0%|          | 4/708709 [00:06<357:57:06,  1.82s/it]\u001b[A\n",
      "Iteration:   0%|          | 5/708709 [00:07<299:30:51,  1.52s/it]\u001b[A\n",
      "Iteration:   0%|          | 6/708709 [00:07<246:09:31,  1.25s/it]\u001b[A\n",
      "Iteration:   0%|          | 7/708709 [00:08<220:57:55,  1.12s/it]\u001b[A\n",
      "Iteration:   0%|          | 8/708709 [00:09<203:20:23,  1.03s/it]\u001b[A\n",
      "Iteration:   0%|          | 9/708709 [00:09<178:19:42,  1.10it/s]\u001b[A\n",
      "Iteration:   0%|          | 10/708709 [00:10<173:31:42,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 11/708709 [00:11<170:07:58,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 12/708709 [00:12<168:06:30,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 13/708709 [00:13<166:57:06,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 14/708709 [00:14<166:15:19,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 15/708709 [00:14<165:38:54,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 16/708709 [00:15<165:20:17,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 17/708709 [00:16<165:10:41,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 18/708709 [00:17<165:02:14,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 19/708709 [00:18<164:55:26,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 20/708709 [00:19<164:52:27,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 21/708709 [00:19<151:34:17,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 22/708709 [00:20<154:49:41,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 23/708709 [00:21<157:26:15,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 24/708709 [00:22<159:36:52,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 25/708709 [00:23<161:04:21,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 26/708709 [00:23<149:15:18,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 27/708709 [00:24<153:26:26,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 28/708709 [00:25<156:55:23,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 29/708709 [00:25<146:35:44,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 30/708709 [00:26<152:13:35,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 31/708709 [00:27<143:15:59,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 32/708709 [00:28<150:01:06,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 33/708709 [00:29<154:44:18,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 34/708709 [00:29<158:07:39,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 35/708709 [00:30<147:28:24,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 36/708709 [00:31<139:54:47,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 37/708709 [00:32<147:36:24,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 38/708709 [00:32<153:02:45,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 39/708709 [00:33<156:55:34,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 40/708709 [00:34<146:36:00,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 41/708709 [00:34<139:21:37,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 42/708709 [00:35<134:19:57,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 43/708709 [00:36<130:47:38,  1.51it/s]\u001b[A\n",
      "Iteration:   0%|          | 44/708709 [00:36<128:16:38,  1.53it/s]\u001b[A\n",
      "Iteration:   0%|          | 45/708709 [00:37<139:35:10,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 46/708709 [00:38<147:28:44,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 47/708709 [00:39<152:55:02,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 48/708709 [00:40<156:52:01,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 49/708709 [00:40<146:32:18,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 50/708709 [00:41<139:20:58,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 51/708709 [00:42<147:19:45,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 52/708709 [00:43<153:10:27,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 53/708709 [00:43<157:01:40,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 54/708709 [00:44<146:40:22,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 55/708709 [00:45<152:24:46,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 56/708709 [00:46<156:29:43,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 57/708709 [00:46<146:18:43,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 58/708709 [00:47<152:14:03,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 59/708709 [00:48<156:19:51,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 60/708709 [00:49<146:12:15,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 61/708709 [00:50<152:09:13,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 62/708709 [00:50<155:59:22,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 63/708709 [00:51<145:28:54,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 64/708709 [00:52<151:35:21,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 65/708709 [00:52<143:02:14,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 66/708709 [00:53<137:06:52,  1.44it/s]\u001b[A\n",
      "Iteration:   0%|          | 67/708709 [00:54<145:56:01,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 68/708709 [00:55<152:07:13,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 69/708709 [00:56<157:07:31,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 70/708709 [00:57<162:05:56,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 71/708709 [00:57<166:50:50,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 72/708709 [00:58<156:39:42,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 73/708709 [00:59<137:13:00,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 74/708709 [00:59<135:59:59,  1.45it/s]\u001b[A\n",
      "Iteration:   0%|          | 75/708709 [01:00<135:10:47,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 76/708709 [01:01<148:55:35,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 77/708709 [01:02<143:55:35,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 78/708709 [01:02<140:21:43,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 79/708709 [01:03<151:54:19,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 80/708709 [01:04<145:47:59,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 81/708709 [01:04<141:20:39,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 82/708709 [01:05<152:15:53,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 83/708709 [01:06<159:24:25,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 84/708709 [01:07<150:37:06,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 85/708709 [01:08<158:40:51,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 86/708709 [01:08<150:07:02,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 87/708709 [01:09<157:27:22,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 88/708709 [01:10<162:56:32,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 89/708709 [01:11<166:43:31,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 90/708709 [01:12<155:31:00,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 91/708709 [01:13<161:28:15,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 92/708709 [01:14<165:40:22,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 93/708709 [01:14<168:38:53,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 94/708709 [01:15<170:47:46,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 95/708709 [01:16<172:14:19,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 96/708709 [01:17<172:46:48,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 97/708709 [01:18<173:10:36,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 98/708709 [01:19<159:38:25,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 99/708709 [01:19<150:06:44,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 100/708709 [01:20<157:13:43,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 101/708709 [01:21<162:40:32,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 102/708709 [01:22<166:15:16,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 103/708709 [01:23<168:23:36,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 104/708709 [01:24<156:17:16,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 105/708709 [01:24<161:36:08,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 106/708709 [01:25<165:24:53,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 107/708709 [01:26<167:59:34,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 108/708709 [01:27<169:52:10,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 109/708709 [01:28<171:30:47,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 110/708709 [01:29<159:01:42,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 111/708709 [01:29<164:05:45,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 112/708709 [01:30<167:35:22,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 113/708709 [01:31<156:20:14,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 114/708709 [01:32<162:11:10,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 115/708709 [01:33<152:15:44,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 116/708709 [01:33<158:55:17,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 117/708709 [01:34<149:50:49,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 118/708709 [01:35<157:07:20,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 119/708709 [01:36<162:15:51,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 120/708709 [01:37<165:46:52,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 121/708709 [01:37<154:40:16,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 122/708709 [01:38<160:51:07,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 123/708709 [01:39<165:14:26,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 124/708709 [01:40<154:39:05,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 125/708709 [01:41<147:11:04,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 126/708709 [01:41<155:23:14,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 127/708709 [01:42<160:59:32,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 128/708709 [01:43<164:46:42,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 129/708709 [01:44<166:58:50,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 130/708709 [01:45<154:45:11,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 131/708709 [01:46<160:17:58,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 132/708709 [01:46<150:35:59,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 133/708709 [01:47<157:21:21,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 134/708709 [01:48<148:07:33,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 135/708709 [01:48<142:40:51,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 136/708709 [01:49<152:36:23,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 137/708709 [01:50<159:12:41,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 138/708709 [01:51<163:32:27,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 139/708709 [01:52<166:45:38,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 140/708709 [01:53<155:20:44,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 141/708709 [01:53<147:21:33,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 142/708709 [01:54<141:49:19,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 143/708709 [01:55<137:43:50,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 144/708709 [01:55<148:34:57,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 145/708709 [01:56<156:17:25,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 146/708709 [01:57<148:22:21,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 147/708709 [01:58<156:38:39,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 148/708709 [01:59<148:33:31,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 149/708709 [01:59<156:18:12,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 150/708709 [02:00<161:38:10,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 151/708709 [02:01<165:40:30,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 152/708709 [02:02<168:33:12,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 153/708709 [02:03<170:46:39,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 154/708709 [02:04<158:27:20,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 155/708709 [02:05<163:35:38,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 156/708709 [02:05<166:51:33,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 157/708709 [02:06<169:21:11,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 158/708709 [02:07<157:24:55,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 159/708709 [02:08<148:45:32,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 160/708709 [02:09<156:40:49,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 161/708709 [02:09<162:23:21,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 162/708709 [02:10<166:46:26,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 163/708709 [02:11<169:46:18,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 164/708709 [02:12<172:06:39,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 165/708709 [02:13<173:17:10,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 166/708709 [02:14<174:08:52,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 167/708709 [02:15<174:20:56,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 168/708709 [02:16<174:21:36,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 169/708709 [02:16<160:41:58,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 170/708709 [02:17<165:06:53,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 171/708709 [02:18<168:00:13,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 172/708709 [02:19<170:12:55,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 173/708709 [02:20<171:57:20,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 174/708709 [02:21<173:12:51,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 175/708709 [02:22<174:04:37,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 176/708709 [02:23<174:15:06,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 177/708709 [02:23<160:35:00,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 178/708709 [02:24<165:00:11,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 179/708709 [02:25<154:48:58,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 180/708709 [02:25<135:11:07,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 181/708709 [02:26<146:40:32,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 182/708709 [02:27<141:04:51,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 183/708709 [02:28<150:41:57,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 184/708709 [02:28<144:02:50,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 185/708709 [02:29<139:29:50,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 186/708709 [02:30<150:29:56,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 187/708709 [02:31<144:07:57,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 188/708709 [02:31<153:31:40,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 189/708709 [02:32<146:21:18,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 190/708709 [02:33<155:12:39,  1.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 191/708709 [02:34<160:57:23,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 192/708709 [02:35<165:12:45,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 193/708709 [02:35<154:34:28,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 194/708709 [02:36<160:57:17,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 195/708709 [02:37<165:05:12,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 196/708709 [02:38<168:12:21,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 197/708709 [02:39<170:29:16,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 198/708709 [02:40<171:40:04,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 199/708709 [02:41<172:17:33,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 200/708709 [02:41<158:40:37,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 201/708709 [02:42<162:56:40,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 202/708709 [02:43<153:03:19,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 203/708709 [02:44<160:18:44,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 204/708709 [02:45<165:00:48,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 205/708709 [02:46<168:12:22,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 206/708709 [02:47<170:42:14,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 207/708709 [02:47<172:12:13,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 208/708709 [02:48<173:14:37,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 209/708709 [02:49<173:37:49,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 210/708709 [02:50<173:53:41,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 211/708709 [02:51<174:24:10,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 212/708709 [02:52<160:46:51,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 213/708709 [02:53<164:43:30,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 214/708709 [02:53<153:57:11,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 215/708709 [02:54<146:20:55,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 216/708709 [02:54<141:03:05,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 217/708709 [02:55<151:00:44,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 218/708709 [02:56<157:57:47,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 219/708709 [02:57<163:14:38,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 220/708709 [02:58<166:38:16,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 221/708709 [02:58<143:10:25,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 222/708709 [02:59<152:20:48,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 223/708709 [03:00<145:28:48,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 224/708709 [03:01<140:29:48,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 225/708709 [03:02<150:19:58,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 226/708709 [03:02<157:25:46,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 227/708709 [03:03<162:48:52,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 228/708709 [03:04<166:23:03,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 229/708709 [03:05<168:48:37,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 230/708709 [03:06<156:47:22,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 231/708709 [03:06<148:17:07,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 232/708709 [03:07<156:28:57,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 233/708709 [03:08<148:27:06,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 234/708709 [03:09<156:44:43,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 235/708709 [03:10<162:41:44,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 236/708709 [03:11<167:00:21,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 237/708709 [03:12<169:29:14,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 238/708709 [03:12<171:06:06,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 239/708709 [03:13<158:23:12,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 240/708709 [03:14<149:31:24,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 241/708709 [03:15<157:02:43,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 242/708709 [03:15<148:39:55,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 243/708709 [03:16<157:12:57,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 244/708709 [03:17<162:54:26,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 245/708709 [03:18<152:43:28,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 246/708709 [03:19<159:25:35,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 247/708709 [03:20<164:16:45,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 248/708709 [03:20<167:19:13,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 249/708709 [03:21<169:37:59,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 250/708709 [03:22<171:24:21,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 251/708709 [03:23<172:29:19,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 252/708709 [03:24<173:24:41,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 253/708709 [03:25<173:44:42,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 254/708709 [03:26<173:46:35,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 255/708709 [03:27<174:09:53,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 256/708709 [03:27<174:14:56,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 257/708709 [03:28<160:33:54,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 258/708709 [03:29<164:48:23,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 259/708709 [03:30<168:20:41,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 260/708709 [03:31<170:36:49,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 261/708709 [03:32<172:28:17,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 262/708709 [03:33<173:29:15,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 263/708709 [03:33<160:07:53,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 264/708709 [03:34<164:43:54,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 265/708709 [03:35<168:06:37,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 266/708709 [03:36<144:30:07,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 267/708709 [03:36<153:29:57,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 268/708709 [03:37<146:01:34,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 269/708709 [03:38<154:29:47,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 270/708709 [03:39<146:43:17,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 271/708709 [03:39<141:24:00,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 272/708709 [03:40<151:38:35,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 273/708709 [03:41<144:49:11,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 274/708709 [03:42<153:38:29,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 275/708709 [03:42<146:14:08,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 276/708709 [03:43<140:59:22,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 277/708709 [03:44<137:13:39,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 278/708709 [03:45<148:16:51,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 279/708709 [03:45<142:20:42,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 280/708709 [03:46<152:11:48,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 281/708709 [03:47<159:11:34,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 282/708709 [03:48<150:07:04,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 283/708709 [03:49<157:40:09,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 284/708709 [03:49<149:16:12,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 285/708709 [03:50<143:07:16,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 286/708709 [03:50<138:43:45,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 287/708709 [03:51<149:10:34,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 288/708709 [03:52<156:33:08,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 289/708709 [03:53<161:52:38,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 290/708709 [03:54<151:53:21,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 291/708709 [03:54<132:57:09,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 292/708709 [03:55<145:38:57,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 293/708709 [03:56<140:35:33,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 294/708709 [03:56<136:57:47,  1.44it/s]\u001b[A\n",
      "Iteration:   0%|          | 295/708709 [03:57<134:26:44,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 296/708709 [03:58<132:41:12,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 297/708709 [03:59<145:02:39,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 298/708709 [04:00<153:51:16,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 299/708709 [04:00<146:16:07,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 300/708709 [04:01<155:00:09,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 301/708709 [04:02<160:51:58,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 302/708709 [04:03<164:47:05,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 303/708709 [04:04<167:51:49,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 304/708709 [04:05<170:09:36,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 305/708709 [04:05<158:02:29,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 306/708709 [04:06<149:33:41,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 307/708709 [04:07<156:58:35,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 308/708709 [04:08<162:08:07,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 309/708709 [04:08<152:02:21,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 310/708709 [04:09<144:58:13,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 311/708709 [04:10<153:30:00,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 312/708709 [04:11<159:23:16,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 313/708709 [04:11<149:55:49,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 314/708709 [04:12<157:10:58,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 315/708709 [04:13<162:02:59,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 316/708709 [04:14<151:50:00,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 317/708709 [04:15<158:43:24,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 318/708709 [04:16<163:59:45,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 319/708709 [04:16<153:28:14,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 320/708709 [04:17<159:46:30,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 321/708709 [04:18<164:28:09,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 322/708709 [04:19<167:24:46,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 323/708709 [04:20<169:44:04,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 324/708709 [04:21<171:36:45,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 325/708709 [04:22<172:31:20,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 326/708709 [04:22<173:27:23,  1.13it/s]\u001b[A\n",
      "Iteration:   0%|          | 327/708709 [04:23<160:20:26,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 328/708709 [04:24<164:36:34,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 329/708709 [04:25<167:12:33,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 330/708709 [04:26<169:14:59,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 331/708709 [04:27<170:50:14,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 332/708709 [04:27<158:02:10,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 333/708709 [04:28<162:51:48,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 334/708709 [04:29<166:15:09,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 335/708709 [04:30<154:58:24,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 336/708709 [04:31<160:47:52,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 337/708709 [04:31<151:06:57,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 338/708709 [04:32<158:25:34,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 339/708709 [04:33<149:32:41,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 340/708709 [04:34<156:42:29,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 341/708709 [04:35<162:16:20,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 342/708709 [04:35<152:17:37,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 343/708709 [04:36<158:51:24,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 344/708709 [04:37<149:49:31,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 345/708709 [04:38<157:32:44,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 346/708709 [04:39<162:40:36,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 347/708709 [04:39<166:26:59,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 348/708709 [04:40<169:14:39,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 349/708709 [04:41<157:08:00,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 350/708709 [04:42<162:20:16,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 351/708709 [04:43<165:53:08,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 352/708709 [04:44<168:27:25,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 353/708709 [04:45<169:56:28,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 354/708709 [04:45<157:31:42,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 355/708709 [04:46<148:51:59,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 356/708709 [04:47<156:28:49,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 357/708709 [04:48<161:54:22,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 358/708709 [04:49<165:35:52,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 359/708709 [04:49<154:35:45,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 360/708709 [04:50<160:30:13,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 361/708709 [04:51<164:52:01,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 362/708709 [04:52<154:15:01,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 363/708709 [04:53<160:14:27,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 364/708709 [04:53<150:44:06,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 365/708709 [04:54<158:02:55,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 366/708709 [04:55<163:18:04,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 367/708709 [04:56<166:33:49,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 368/708709 [04:57<169:07:55,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 369/708709 [04:57<157:00:10,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 370/708709 [04:58<148:27:45,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 371/708709 [04:59<156:07:02,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 372/708709 [05:00<147:49:44,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 373/708709 [05:00<155:46:53,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 374/708709 [05:01<161:19:25,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 375/708709 [05:02<165:10:03,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 376/708709 [05:03<154:09:38,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 377/708709 [05:04<146:15:23,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 378/708709 [05:04<154:19:26,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 379/708709 [05:05<160:08:17,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 380/708709 [05:06<164:39:52,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 381/708709 [05:07<167:29:23,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 382/708709 [05:08<169:32:06,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 383/708709 [05:09<171:22:16,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 384/708709 [05:10<158:33:50,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 385/708709 [05:10<163:17:58,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 386/708709 [05:11<166:34:41,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 387/708709 [05:12<168:47:57,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 388/708709 [05:13<170:21:30,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 389/708709 [05:14<157:53:07,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 390/708709 [05:15<162:51:06,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 391/708709 [05:15<166:07:49,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 392/708709 [05:16<168:31:33,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 393/708709 [05:17<156:33:13,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 394/708709 [05:18<161:53:28,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 395/708709 [05:19<151:46:06,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 396/708709 [05:19<158:27:22,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 397/708709 [05:20<163:28:53,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 398/708709 [05:21<167:32:27,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 399/708709 [05:22<156:30:18,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 400/708709 [05:23<162:18:56,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 401/708709 [05:24<165:56:59,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 402/708709 [05:25<168:29:44,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 403/708709 [05:25<170:13:37,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 404/708709 [05:26<171:09:14,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 405/708709 [05:27<158:18:32,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 406/708709 [05:28<163:07:53,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 407/708709 [05:28<140:45:29,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 408/708709 [05:29<150:29:43,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 409/708709 [05:30<157:22:48,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 410/708709 [05:31<162:19:02,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 411/708709 [05:32<151:48:09,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 412/708709 [05:32<157:50:36,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 413/708709 [05:33<148:36:46,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 414/708709 [05:34<142:10:53,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 415/708709 [05:34<137:57:01,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 416/708709 [05:35<135:05:09,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 417/708709 [05:36<146:37:00,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 418/708709 [05:37<154:42:11,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 419/708709 [05:38<160:29:09,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 420/708709 [05:39<164:34:55,  1.20it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 421/708709 [05:39<167:26:27,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 422/708709 [05:40<155:47:31,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 423/708709 [05:41<161:26:12,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 424/708709 [05:42<165:15:45,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 425/708709 [05:43<168:17:59,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 426/708709 [05:44<170:25:00,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 427/708709 [05:44<157:54:17,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 428/708709 [05:45<149:08:19,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 429/708709 [05:46<156:52:40,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 430/708709 [05:47<148:25:50,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 431/708709 [05:47<156:05:05,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 432/708709 [05:48<147:50:01,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 433/708709 [05:49<142:04:25,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 434/708709 [05:50<151:30:57,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 435/708709 [05:51<158:01:44,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 436/708709 [05:51<149:06:08,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 437/708709 [05:52<156:26:17,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 438/708709 [05:53<147:52:25,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 439/708709 [05:53<141:37:46,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 440/708709 [05:54<151:06:03,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 441/708709 [05:55<157:58:45,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 442/708709 [05:56<149:03:40,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 443/708709 [05:57<155:54:02,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 444/708709 [05:57<147:15:51,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 445/708709 [05:58<155:08:33,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 446/708709 [05:59<161:15:46,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 447/708709 [06:00<151:19:42,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 448/708709 [06:00<144:02:38,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 449/708709 [06:01<127:05:37,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 450/708709 [06:01<127:02:16,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 451/708709 [06:02<140:39:06,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 452/708709 [06:03<150:19:41,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 453/708709 [06:04<143:44:13,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 454/708709 [06:04<139:14:05,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 455/708709 [06:05<149:38:56,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 456/708709 [06:06<157:22:32,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 457/708709 [06:07<163:00:46,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 458/708709 [06:08<166:46:58,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 459/708709 [06:09<155:19:58,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 460/708709 [06:09<147:10:06,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 461/708709 [06:10<141:22:53,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 462/708709 [06:11<137:17:53,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 463/708709 [06:12<148:03:34,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 464/708709 [06:12<155:10:43,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 465/708709 [06:13<160:30:03,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 466/708709 [06:14<150:45:16,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 467/708709 [06:15<157:23:55,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 468/708709 [06:16<162:11:45,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 469/708709 [06:16<151:56:06,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 470/708709 [06:17<158:37:50,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 471/708709 [06:18<163:20:33,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 472/708709 [06:19<140:59:44,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 473/708709 [06:19<150:50:36,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 474/708709 [06:20<144:08:55,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 475/708709 [06:21<152:51:34,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 476/708709 [06:22<145:23:43,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 477/708709 [06:23<153:39:28,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 478/708709 [06:23<159:40:46,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 479/708709 [06:24<163:43:46,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 480/708709 [06:25<166:37:10,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 481/708709 [06:26<168:52:34,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 482/708709 [06:27<170:16:27,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 483/708709 [06:28<171:09:35,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 484/708709 [06:29<171:45:21,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 485/708709 [06:29<158:25:23,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 486/708709 [06:30<162:27:10,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 487/708709 [06:31<165:36:19,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 488/708709 [06:32<168:06:35,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 489/708709 [06:33<156:13:45,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 490/708709 [06:34<161:36:13,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 491/708709 [06:34<165:19:46,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 492/708709 [06:35<167:44:12,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 493/708709 [06:36<169:24:52,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 494/708709 [06:37<170:52:00,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 495/708709 [06:38<158:15:39,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 496/708709 [06:38<149:21:31,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 497/708709 [06:39<142:54:00,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 498/708709 [06:40<151:05:59,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 499/708709 [06:41<157:10:54,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 500/708709 [06:42<162:15:27,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 501/708709 [06:42<152:31:17,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 502/708709 [06:43<159:06:59,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 503/708709 [06:44<163:42:30,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 504/708709 [06:45<152:49:46,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 505/708709 [06:45<144:27:49,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 506/708709 [06:46<138:47:21,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 507/708709 [06:47<148:35:01,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 508/708709 [06:48<156:11:17,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 509/708709 [06:48<148:03:21,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 510/708709 [06:49<155:40:29,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 511/708709 [06:50<161:09:01,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 512/708709 [06:51<165:05:03,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 513/708709 [06:52<154:09:22,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 514/708709 [06:52<146:29:49,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 515/708709 [06:53<141:07:16,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 516/708709 [06:54<137:22:58,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 517/708709 [06:55<148:06:27,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 518/708709 [06:55<155:33:16,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 519/708709 [06:56<161:00:07,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 520/708709 [06:57<165:18:51,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 521/708709 [06:58<167:59:18,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 522/708709 [06:59<156:09:35,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 523/708709 [07:00<161:31:36,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 524/708709 [07:01<165:13:34,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 525/708709 [07:01<167:44:33,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 526/708709 [07:02<169:25:51,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 527/708709 [07:03<170:41:33,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 528/708709 [07:04<157:45:38,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 529/708709 [07:04<148:30:46,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 530/708709 [07:05<155:22:44,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 531/708709 [07:06<160:10:58,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 532/708709 [07:07<149:53:57,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 533/708709 [07:07<142:48:12,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 534/708709 [07:08<138:00:42,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 535/708709 [07:09<134:43:35,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 536/708709 [07:10<146:11:47,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 537/708709 [07:11<154:21:56,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 538/708709 [07:11<134:26:45,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 539/708709 [07:12<132:11:39,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 540/708709 [07:12<130:36:42,  1.51it/s]\u001b[A\n",
      "Iteration:   0%|          | 541/708709 [07:13<143:11:23,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 542/708709 [07:14<152:10:37,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 543/708709 [07:15<158:39:27,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 544/708709 [07:16<163:17:35,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 545/708709 [07:16<152:45:22,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 546/708709 [07:17<145:14:41,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 547/708709 [07:18<153:42:12,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 548/708709 [07:19<160:06:26,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 549/708709 [07:20<164:26:47,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 550/708709 [07:21<167:04:13,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 551/708709 [07:22<168:49:18,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 552/708709 [07:22<156:30:37,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 553/708709 [07:23<147:40:12,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 554/708709 [07:24<154:44:55,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 555/708709 [07:25<160:05:31,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 556/708709 [07:25<164:00:17,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 557/708709 [07:26<166:13:04,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 558/708709 [07:27<154:45:11,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 559/708709 [07:28<146:43:01,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 560/708709 [07:28<140:28:37,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 561/708709 [07:29<150:12:48,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 562/708709 [07:30<131:44:46,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 563/708709 [07:30<130:17:53,  1.51it/s]\u001b[A\n",
      "Iteration:   0%|          | 564/708709 [07:31<143:06:19,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 565/708709 [07:32<152:23:20,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 566/708709 [07:33<158:49:42,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 567/708709 [07:34<162:50:18,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 568/708709 [07:35<165:49:53,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 569/708709 [07:36<168:06:48,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 570/708709 [07:36<169:41:19,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 571/708709 [07:37<170:57:23,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 572/708709 [07:38<171:50:02,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 573/708709 [07:39<172:19:38,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 574/708709 [07:40<159:00:38,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 575/708709 [07:40<149:45:34,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 576/708709 [07:41<156:46:14,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 577/708709 [07:42<147:58:08,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 578/708709 [07:43<141:36:26,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 579/708709 [07:43<151:01:07,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 580/708709 [07:44<157:41:51,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 581/708709 [07:45<162:17:40,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 582/708709 [07:46<165:27:00,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 583/708709 [07:47<154:07:20,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 584/708709 [07:48<159:48:10,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 585/708709 [07:48<163:45:37,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 586/708709 [07:49<166:35:43,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 587/708709 [07:50<155:02:06,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 588/708709 [07:51<160:43:12,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 589/708709 [07:52<164:28:26,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 590/708709 [07:53<167:07:50,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 591/708709 [07:53<168:53:33,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 592/708709 [07:54<170:02:48,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 593/708709 [07:55<170:33:42,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 594/708709 [07:56<171:13:45,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 595/708709 [07:57<171:42:40,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 596/708709 [07:58<172:07:20,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 597/708709 [07:59<158:51:03,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 598/708709 [07:59<163:25:31,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 599/708709 [08:00<166:30:13,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 600/708709 [08:01<154:40:54,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 601/708709 [08:02<146:19:06,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 602/708709 [08:02<154:15:02,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 603/708709 [08:03<159:54:19,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 604/708709 [08:04<150:14:24,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 605/708709 [08:05<156:59:15,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 606/708709 [08:06<148:17:54,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 607/708709 [08:06<155:46:40,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 608/708709 [08:07<161:03:36,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 609/708709 [08:08<164:46:58,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 610/708709 [08:09<167:32:50,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 611/708709 [08:10<169:30:33,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 612/708709 [08:11<157:09:23,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 613/708709 [08:11<162:11:52,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 614/708709 [08:12<165:43:04,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 615/708709 [08:13<168:01:42,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 616/708709 [08:14<169:50:28,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 617/708709 [08:15<157:12:17,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 618/708709 [08:16<161:35:19,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 619/708709 [08:17<164:26:52,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 620/708709 [08:17<152:52:49,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 621/708709 [08:18<158:55:36,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 622/708709 [08:19<149:43:04,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 623/708709 [08:20<156:45:04,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 624/708709 [08:20<161:18:44,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 625/708709 [08:21<150:59:07,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 626/708709 [08:22<157:21:21,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 627/708709 [08:23<161:54:00,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 628/708709 [08:24<165:31:27,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 629/708709 [08:25<168:03:08,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 630/708709 [08:26<169:39:12,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 631/708709 [08:26<156:55:20,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 632/708709 [08:27<161:39:16,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 633/708709 [08:28<151:31:11,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 634/708709 [08:29<157:56:40,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 635/708709 [08:29<162:29:17,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 636/708709 [08:30<165:55:34,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 637/708709 [08:31<168:17:25,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 638/708709 [08:32<156:25:00,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 639/708709 [08:33<161:08:55,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 640/708709 [08:34<164:37:23,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 641/708709 [08:34<167:10:56,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 642/708709 [08:35<143:21:43,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 643/708709 [08:36<138:10:06,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 644/708709 [08:36<148:05:36,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 645/708709 [08:37<141:40:58,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 646/708709 [08:38<150:57:12,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 647/708709 [08:39<157:22:16,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 648/708709 [08:40<162:27:33,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 649/708709 [08:41<166:28:25,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 650/708709 [08:42<168:53:04,  1.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 651/708709 [08:42<156:51:08,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 652/708709 [08:43<162:20:07,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 653/708709 [08:44<165:50:55,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 654/708709 [08:45<154:42:47,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 655/708709 [08:45<160:55:12,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 656/708709 [08:46<164:58:10,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 657/708709 [08:47<153:53:14,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 658/708709 [08:48<146:11:00,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 659/708709 [08:48<140:39:45,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 660/708709 [08:49<150:26:46,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 661/708709 [08:50<143:23:06,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 662/708709 [08:51<151:54:50,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 663/708709 [08:52<157:49:16,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 664/708709 [08:52<148:32:05,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 665/708709 [08:53<155:36:56,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 666/708709 [08:54<146:53:38,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 667/708709 [08:55<154:11:09,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 668/708709 [08:55<145:59:18,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 669/708709 [08:56<128:30:59,  1.53it/s]\u001b[A\n",
      "Iteration:   0%|          | 670/708709 [08:57<141:17:54,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 671/708709 [08:57<150:26:57,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 672/708709 [08:58<157:10:00,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 673/708709 [08:59<162:13:13,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 674/708709 [09:00<165:33:47,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 675/708709 [09:01<153:58:22,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 676/708709 [09:01<145:46:48,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 677/708709 [09:02<153:48:22,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 678/708709 [09:03<145:45:46,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 679/708709 [09:04<153:51:22,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 680/708709 [09:05<159:56:42,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 681/708709 [09:06<164:18:19,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 682/708709 [09:06<167:03:49,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 683/708709 [09:07<168:53:36,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 684/708709 [09:08<156:35:30,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 685/708709 [09:09<148:01:59,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 686/708709 [09:10<155:20:33,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 687/708709 [09:10<146:47:31,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 688/708709 [09:11<154:32:55,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 689/708709 [09:12<160:23:19,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 690/708709 [09:13<164:19:05,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 691/708709 [09:13<153:06:33,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 692/708709 [09:14<159:02:47,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 693/708709 [09:15<163:29:24,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 694/708709 [09:16<166:28:00,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 695/708709 [09:17<168:30:21,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 696/708709 [09:18<156:24:21,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 697/708709 [09:19<161:30:24,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 698/708709 [09:19<164:36:48,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 699/708709 [09:20<153:31:18,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 700/708709 [09:21<159:26:06,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 701/708709 [09:22<163:29:12,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 702/708709 [09:23<166:22:56,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 703/708709 [09:23<154:46:31,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 704/708709 [09:24<160:28:28,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 705/708709 [09:25<138:53:14,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 706/708709 [09:26<148:41:19,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 707/708709 [09:26<156:09:04,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 708/708709 [09:27<161:09:43,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 709/708709 [09:28<150:54:52,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 710/708709 [09:29<157:07:27,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 711/708709 [09:30<161:24:12,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 712/708709 [09:30<151:02:29,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 713/708709 [09:31<152:55:34,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 714/708709 [09:32<133:33:14,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 715/708709 [09:32<131:34:53,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 716/708709 [09:33<143:14:44,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 717/708709 [09:34<151:36:26,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 718/708709 [09:35<144:07:36,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 719/708709 [09:35<138:55:09,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 720/708709 [09:36<148:59:01,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 721/708709 [09:37<156:16:10,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 722/708709 [09:38<161:31:05,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 723/708709 [09:39<165:21:01,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 724/708709 [09:40<167:49:29,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 725/708709 [09:41<169:28:33,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 726/708709 [09:41<157:00:47,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 727/708709 [09:42<161:35:33,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 728/708709 [09:43<151:12:00,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 729/708709 [09:44<157:46:56,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 730/708709 [09:44<162:26:17,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 731/708709 [09:45<165:17:35,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 732/708709 [09:46<167:31:04,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 733/708709 [09:47<169:14:16,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 734/708709 [09:48<170:45:53,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 735/708709 [09:49<171:37:02,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 736/708709 [09:50<158:31:11,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 737/708709 [09:50<162:57:12,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 738/708709 [09:51<152:23:04,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 739/708709 [09:52<158:10:43,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 740/708709 [09:53<162:17:41,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 741/708709 [09:54<165:00:42,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 742/708709 [09:54<153:48:11,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 743/708709 [09:55<159:38:24,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 744/708709 [09:56<163:57:04,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 745/708709 [09:57<152:52:40,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 746/708709 [09:58<158:54:44,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 747/708709 [09:58<163:06:38,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 748/708709 [09:59<152:46:42,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 749/708709 [10:00<159:11:49,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 750/708709 [10:01<163:48:48,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 751/708709 [10:02<166:37:31,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 752/708709 [10:03<168:35:10,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 753/708709 [10:03<156:07:40,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 754/708709 [10:04<160:48:19,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 755/708709 [10:05<164:01:02,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 756/708709 [10:06<166:43:50,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 757/708709 [10:07<154:53:08,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 758/708709 [10:07<145:59:19,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 759/708709 [10:08<153:43:53,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 760/708709 [10:09<159:44:00,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 761/708709 [10:10<150:13:34,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 762/708709 [10:11<157:04:17,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 763/708709 [10:11<148:17:56,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 764/708709 [10:12<155:23:16,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 765/708709 [10:13<160:32:25,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 766/708709 [10:14<150:48:49,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 767/708709 [10:14<157:26:28,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 768/708709 [10:15<162:12:58,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 769/708709 [10:16<165:44:03,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 770/708709 [10:17<168:21:32,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 771/708709 [10:18<156:16:05,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 772/708709 [10:18<147:53:38,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 773/708709 [10:19<141:53:14,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 774/708709 [10:20<137:30:29,  1.43it/s]\u001b[A\n",
      "Iteration:   0%|          | 775/708709 [10:20<134:20:11,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 776/708709 [10:21<132:06:56,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 777/708709 [10:22<143:54:31,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 778/708709 [10:22<127:10:18,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 779/708709 [10:23<140:51:39,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 780/708709 [10:24<150:44:30,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 781/708709 [10:25<143:40:31,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 782/708709 [10:26<152:27:05,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 783/708709 [10:27<158:49:30,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 784/708709 [10:27<163:19:02,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 785/708709 [10:28<152:43:50,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 786/708709 [10:29<159:17:48,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 787/708709 [10:30<163:35:29,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 788/708709 [10:31<166:26:20,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 789/708709 [10:32<168:26:50,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 790/708709 [10:32<169:40:32,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 791/708709 [10:33<156:52:28,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 792/708709 [10:34<136:24:27,  1.44it/s]\u001b[A\n",
      "Iteration:   0%|          | 793/708709 [10:34<147:19:19,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 794/708709 [10:35<155:31:05,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 795/708709 [10:36<147:18:24,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 796/708709 [10:37<141:18:43,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 797/708709 [10:37<136:55:39,  1.44it/s]\u001b[A\n",
      "Iteration:   0%|          | 798/708709 [10:38<134:02:33,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 799/708709 [10:39<145:41:39,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 800/708709 [10:40<154:01:04,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 801/708709 [10:41<159:23:42,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 802/708709 [10:41<163:32:25,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 803/708709 [10:42<152:49:36,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 804/708709 [10:43<158:34:14,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 805/708709 [10:44<162:26:31,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 806/708709 [10:45<164:55:25,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 807/708709 [10:45<153:26:28,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 808/708709 [10:46<158:58:17,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 809/708709 [10:47<163:11:00,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 810/708709 [10:48<166:29:24,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 811/708709 [10:49<168:41:19,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 812/708709 [10:50<170:05:56,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 813/708709 [10:51<171:10:23,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 814/708709 [10:51<171:56:22,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 815/708709 [10:52<158:29:12,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 816/708709 [10:53<149:03:56,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 817/708709 [10:54<156:07:02,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 818/708709 [10:55<161:24:55,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 819/708709 [10:55<151:28:39,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 820/708709 [10:56<144:11:42,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 821/708709 [10:56<139:01:48,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 822/708709 [10:57<149:19:15,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 823/708709 [10:58<142:55:22,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 824/708709 [10:59<151:58:05,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 825/708709 [11:00<144:43:40,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 826/708709 [11:00<139:45:50,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 827/708709 [11:01<149:44:14,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 828/708709 [11:02<156:23:09,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 829/708709 [11:03<160:56:27,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 830/708709 [11:03<150:54:07,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 831/708709 [11:04<157:30:18,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 832/708709 [11:05<136:45:53,  1.44it/s]\u001b[A\n",
      "Iteration:   0%|          | 833/708709 [11:06<147:14:16,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 834/708709 [11:07<155:02:14,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 835/708709 [11:07<160:29:39,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 836/708709 [11:08<164:28:51,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 837/708709 [11:09<166:41:52,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 838/708709 [11:10<168:33:54,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 839/708709 [11:11<169:56:29,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 840/708709 [11:12<170:02:07,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 841/708709 [11:13<170:38:02,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 842/708709 [11:14<171:52:11,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 843/708709 [11:14<172:26:36,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 844/708709 [11:15<159:16:30,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 845/708709 [11:16<149:57:57,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 846/708709 [11:16<143:29:00,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 847/708709 [11:17<138:35:13,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 848/708709 [11:18<148:36:37,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 849/708709 [11:19<155:36:12,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 850/708709 [11:19<147:06:58,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 851/708709 [11:20<154:55:59,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 852/708709 [11:21<160:09:59,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 853/708709 [11:22<163:55:38,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 854/708709 [11:23<166:43:50,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 855/708709 [11:24<168:37:42,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 856/708709 [11:25<170:02:36,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 857/708709 [11:26<171:06:43,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 858/708709 [11:27<171:47:10,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 859/708709 [11:27<158:18:37,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 860/708709 [11:28<162:18:23,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 861/708709 [11:29<165:04:43,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 862/708709 [11:30<167:31:15,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 863/708709 [11:31<169:13:36,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 864/708709 [11:32<170:34:16,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 865/708709 [11:32<157:36:45,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 866/708709 [11:33<147:55:25,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 867/708709 [11:34<154:16:12,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 868/708709 [11:34<146:02:01,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 869/708709 [11:35<153:37:41,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 870/708709 [11:36<159:26:12,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 871/708709 [11:37<149:50:26,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 872/708709 [11:38<156:37:56,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 873/708709 [11:38<147:58:25,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 874/708709 [11:39<155:47:00,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 875/708709 [11:40<161:20:01,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 876/708709 [11:41<151:07:25,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 877/708709 [11:41<143:51:36,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 878/708709 [11:42<138:42:59,  1.42it/s]\u001b[A\n",
      "Iteration:   0%|          | 879/708709 [11:43<135:12:56,  1.45it/s]\u001b[A\n",
      "Iteration:   0%|          | 880/708709 [11:44<146:29:37,  1.34it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 881/708709 [11:44<154:33:52,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 882/708709 [11:45<160:09:31,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 883/708709 [11:46<150:37:59,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 884/708709 [11:47<157:17:30,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 885/708709 [11:47<148:22:52,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 886/708709 [11:48<155:43:37,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 887/708709 [11:49<161:07:23,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 888/708709 [11:50<151:11:29,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 889/708709 [11:51<157:18:57,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 890/708709 [11:52<161:38:18,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 891/708709 [11:52<151:14:19,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 892/708709 [11:53<157:40:13,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 893/708709 [11:54<148:42:45,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 894/708709 [11:55<155:49:04,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 895/708709 [11:55<147:20:26,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 896/708709 [11:56<154:55:32,  1.27it/s]\u001b[A\n",
      "Iteration:   0%|          | 897/708709 [11:57<159:58:27,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 898/708709 [11:58<163:29:04,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 899/708709 [11:59<166:19:25,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 900/708709 [12:00<168:29:44,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 901/708709 [12:01<169:36:44,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 902/708709 [12:01<170:27:51,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 903/708709 [12:02<171:29:12,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 904/708709 [12:03<172:01:11,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 905/708709 [12:04<172:21:46,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 906/708709 [12:05<172:53:58,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 907/708709 [12:06<159:28:40,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 908/708709 [12:06<149:43:12,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 909/708709 [12:07<142:51:54,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 910/708709 [12:08<151:56:34,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 911/708709 [12:08<144:52:45,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 912/708709 [12:09<153:25:48,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 913/708709 [12:10<158:58:39,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 914/708709 [12:11<149:22:31,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 915/708709 [12:12<155:53:42,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 916/708709 [12:13<160:32:48,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 917/708709 [12:13<164:08:26,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 918/708709 [12:14<166:40:46,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 919/708709 [12:15<168:28:42,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 920/708709 [12:16<169:49:43,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 921/708709 [12:17<157:15:06,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 922/708709 [12:18<161:55:00,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 923/708709 [12:18<151:45:25,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 924/708709 [12:19<157:46:57,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 925/708709 [12:20<162:22:52,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 926/708709 [12:21<165:37:36,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 927/708709 [12:22<167:49:25,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 928/708709 [12:23<169:15:24,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 929/708709 [12:24<170:24:15,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 930/708709 [12:24<157:46:36,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 931/708709 [12:25<162:26:02,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 932/708709 [12:26<165:14:40,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 933/708709 [12:27<167:26:56,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 934/708709 [12:28<169:17:52,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 935/708709 [12:29<170:29:04,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 936/708709 [12:30<171:18:23,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 937/708709 [12:30<171:59:35,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 938/708709 [12:31<172:24:42,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 939/708709 [12:32<172:37:58,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 940/708709 [12:33<159:14:10,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 941/708709 [12:33<149:54:04,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 942/708709 [12:34<156:09:16,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 943/708709 [12:35<146:35:27,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 944/708709 [12:36<140:47:46,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 945/708709 [12:36<149:56:17,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 946/708709 [12:37<156:43:29,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 947/708709 [12:38<161:13:24,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 948/708709 [12:39<151:06:55,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 949/708709 [12:40<157:51:18,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 950/708709 [12:40<149:04:48,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 951/708709 [12:41<142:51:21,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 952/708709 [12:42<151:33:25,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 953/708709 [12:43<157:49:16,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 954/708709 [12:43<136:56:29,  1.44it/s]\u001b[A\n",
      "Iteration:   0%|          | 955/708709 [12:44<134:22:35,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 956/708709 [12:45<145:16:20,  1.35it/s]\u001b[A\n",
      "Iteration:   0%|          | 957/708709 [12:45<139:05:37,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 958/708709 [12:46<148:54:53,  1.32it/s]\u001b[A\n",
      "Iteration:   0%|          | 959/708709 [12:47<156:09:59,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 960/708709 [12:48<147:23:49,  1.33it/s]\u001b[A\n",
      "Iteration:   0%|          | 961/708709 [12:48<141:08:37,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 962/708709 [12:49<150:19:49,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 963/708709 [12:50<157:00:41,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 964/708709 [12:51<161:48:17,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 965/708709 [12:52<139:36:35,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 966/708709 [12:52<135:35:20,  1.45it/s]\u001b[A\n",
      "Iteration:   0%|          | 967/708709 [12:53<146:14:45,  1.34it/s]\u001b[A\n",
      "Iteration:   0%|          | 968/708709 [12:54<154:04:48,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 969/708709 [12:55<159:44:02,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 970/708709 [12:55<149:56:50,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 971/708709 [12:56<156:31:49,  1.26it/s]\u001b[A\n",
      "Iteration:   0%|          | 972/708709 [12:57<161:23:21,  1.22it/s]\u001b[A\n",
      "Iteration:   0%|          | 973/708709 [12:58<164:51:04,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 974/708709 [12:59<167:33:38,  1.17it/s]\u001b[A\n",
      "Iteration:   0%|          | 975/708709 [13:00<169:46:30,  1.16it/s]\u001b[A\n",
      "Iteration:   0%|          | 976/708709 [13:01<171:07:30,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 977/708709 [13:02<171:39:13,  1.15it/s]\u001b[A\n",
      "Iteration:   0%|          | 978/708709 [13:03<172:00:46,  1.14it/s]\u001b[A\n",
      "Iteration:   0%|          | 979/708709 [13:03<158:30:28,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 980/708709 [13:04<162:24:35,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 981/708709 [13:05<151:40:53,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 982/708709 [13:05<143:38:48,  1.37it/s]\u001b[A\n",
      "Iteration:   0%|          | 983/708709 [13:06<152:00:07,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 984/708709 [13:07<144:48:21,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 985/708709 [13:08<152:58:34,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 986/708709 [13:08<144:20:57,  1.36it/s]\u001b[A\n",
      "Iteration:   0%|          | 987/708709 [13:09<152:13:46,  1.29it/s]\u001b[A\n",
      "Iteration:   0%|          | 988/708709 [13:10<158:02:21,  1.24it/s]\u001b[A\n",
      "Iteration:   0%|          | 989/708709 [13:11<161:51:01,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 990/708709 [13:12<164:31:28,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 991/708709 [13:13<166:01:35,  1.18it/s]\u001b[A\n",
      "Iteration:   0%|          | 992/708709 [13:13<142:00:15,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 993/708709 [13:14<150:56:21,  1.30it/s]\u001b[A\n",
      "Iteration:   0%|          | 994/708709 [13:15<157:14:18,  1.25it/s]\u001b[A\n",
      "Iteration:   0%|          | 995/708709 [13:16<161:50:13,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 996/708709 [13:17<165:10:02,  1.19it/s]\u001b[A\n",
      "Iteration:   0%|          | 997/708709 [13:17<154:03:14,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 998/708709 [13:18<159:41:03,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 999/708709 [13:19<163:48:44,  1.20it/s]\u001b[A\n",
      "Iteration:   0%|          | 1000/708709 [13:20<153:06:01,  1.28it/s]\u001b[A\n",
      "Iteration:   0%|          | 1001/708709 [13:21<159:22:02,  1.23it/s]\u001b[A\n",
      "Iteration:   0%|          | 1002/708709 [13:21<149:59:46,  1.31it/s]\u001b[AException ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f2936306400>\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/weakref.py\", line 109, in remove\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "KeyboardInterrupt\n",
      "09/10/2019 22:28:21 - ERROR - root -   Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "09/10/2019 22:28:21 - INFO - root -   \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-62521f6ea179>\", line 178, in <module>\n",
      "    global_step, tr_loss = train(args, train_dataset, eval_dataset, model, tokenizer)\n",
      "  File \"<ipython-input-4-8302484b3cec>\", line 83, in train\n",
      "    loss.backward()\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/torch/tensor.py\", line 118, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 93, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "## Required parameters\n",
    "parser.add_argument(\"--data_dir\", default='/mnt/scratch/chenqu/aol/preprocessed/', type=str, required=False,\n",
    "                    help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "parser.add_argument(\"--model_type\", default='hier', type=str, required=False,\n",
    "                    help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "parser.add_argument(\"--model_name_or_path\", default='/mnt/scratch/chenqu/huggingface/', type=str, required=False,\n",
    "                    help=\"Path to pre-trained model or shortcut name\")\n",
    "parser.add_argument(\"--task_name\", default='stateful_search', type=str, required=False,\n",
    "                    help=\"The name of the task to train\")\n",
    "parser.add_argument(\"--output_dir\", default='/mnt/scratch/chenqu/stateful_search/20000/', type=str, required=False,\n",
    "                    help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "\n",
    "## Other parameters\n",
    "parser.add_argument(\"--config_name\", default=\"\", type=str,\n",
    "                    help=\"Pretrained config name or path if not the same as model_name\")\n",
    "parser.add_argument(\"--tokenizer_name\", default=\"\", type=str,\n",
    "                    help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "parser.add_argument(\"--cache_dir\", default=\"\", type=str,\n",
    "                    help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "parser.add_argument(\"--max_seq_length\", default=128, type=int,\n",
    "                    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "                         \"than this will be truncated, sequences shorter will be padded.\")\n",
    "parser.add_argument(\"--do_train\", default=True, type=str2bool,\n",
    "                    help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\", default=True, type=str2bool,\n",
    "                    help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\"--evaluate_during_training\", default=True, type=str2bool,\n",
    "                    help=\"Run evaluation during training at each logging step.\")\n",
    "parser.add_argument(\"--do_lower_case\", default=True, type=str2bool,\n",
    "                    help=\"Set this flag if you are using an uncased model.\")\n",
    "\n",
    "parser.add_argument(\"--per_gpu_train_batch_size\", default=4, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for training.\")\n",
    "parser.add_argument(\"--per_gpu_eval_batch_size\", default=2, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "parser.add_argument(\"--per_gpu_test_batch_size\", default=2, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for testing.\")\n",
    "parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                    help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "parser.add_argument(\"--learning_rate\", default=3e-5, type=float,\n",
    "                    help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                    help=\"Weight decay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                    help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
    "                    help=\"Max gradient norm.\")\n",
    "parser.add_argument(\"--num_train_epochs\", default=3.0, type=float,\n",
    "                    help=\"Total number of training epochs to perform.\")\n",
    "parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
    "                    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
    "                    help=\"Linear warmup over warmup_steps.\")\n",
    "\n",
    "parser.add_argument('--logging_steps', type=int, default=5,\n",
    "                    help=\"Log and save checkpoint every X updates steps.\")\n",
    "parser.add_argument('--save_steps', type=int, default=5000,\n",
    "                    help=\"Save checkpoint every X updates steps, this is disabled in our code\")\n",
    "parser.add_argument(\"--eval_all_checkpoints\", default=False, type=str2bool,\n",
    "                    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\")\n",
    "parser.add_argument(\"--no_cuda\", default=False, type=str2bool,\n",
    "                    help=\"Avoid using CUDA when available\")\n",
    "parser.add_argument('--overwrite_output_dir', default=True, type=str2bool,\n",
    "                    help=\"Overwrite the content of the output directory\")\n",
    "parser.add_argument('--overwrite_cache', action='store_true',\n",
    "                    help=\"Overwrite the cached training and evaluation sets\")\n",
    "parser.add_argument('--seed', type=int, default=42,\n",
    "                    help=\"random seed for initialization\")\n",
    "\n",
    "parser.add_argument('--fp16', default=False, type=str2bool,\n",
    "                    help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "parser.add_argument('--fp16_opt_level', type=str, default='O1',\n",
    "                    help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                         \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
    "                    help=\"For distributed training: local_rank\")\n",
    "parser.add_argument('--server_ip', type=str, default='', help=\"For distant debugging.\")\n",
    "parser.add_argument('--server_port', type=str, default='', help=\"For distant debugging.\")\n",
    "\n",
    "# parameters we added\n",
    "parser.add_argument(\"--include_skipped\", default=True, type=str2bool, required=False,\n",
    "                    help=\"whether to include the skipped doc from prev turn\")\n",
    "parser.add_argument(\"--enable_turn_id_embeddings\", default=True, type=str2bool, required=False,\n",
    "                    help=\"whether to enable turn id embeddings\")\n",
    "parser.add_argument(\"--enable_component_embeddings\", default=True, type=str2bool, required=False,\n",
    "                    help=\"whether to enable component embeddings\")\n",
    "parser.add_argument(\"--load_small\", default=True, type=str2bool, required=False,\n",
    "                    help=\"whether to just a small portion of data during development\")\n",
    "parser.add_argument(\"--dataset\", default='aol', type=str, required=False,\n",
    "                    help=\"aol or msmarco. For bing data, we do not use the first query in a session\")\n",
    "parser.add_argument(\"--history_num\", default=2, type=int, required=False,\n",
    "                    help=\"number of history turns to concat\")\n",
    "parser.add_argument(\"--num_workers\", default=2, type=int, required=False,\n",
    "                    help=\"number of workers for dataloader\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n",
    "\n",
    "# Setup distant debugging if needed\n",
    "if args.server_ip and args.server_port:\n",
    "    # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
    "    import ptvsd\n",
    "    print(\"Waiting for debugger attach\")\n",
    "    ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
    "    ptvsd.wait_for_attach()\n",
    "\n",
    "# Setup CUDA, GPU & distributed training\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "    args.n_gpu = 1\n",
    "args.device = device\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n",
    "logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "                args.local_rank, device, args.n_gpu, bool(args.local_rank != -1), args.fp16)\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "\n",
    "args.task_name = args.task_name.lower()\n",
    "# if args.task_name not in processors:\n",
    "#     raise ValueError(\"Task not found: %s\" % (args.task_name))\n",
    "# processor = processors[args.task_name]()\n",
    "args.output_mode = output_modes[args.task_name]\n",
    "label_list = [\"False\", \"True\"]\n",
    "num_labels = len(label_list)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "if args.local_rank not in [-1, 0]:\n",
    "    torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "args.model_type = args.model_type.lower()\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path, num_labels=num_labels, finetuning_task=args.task_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else args.model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "tokenizer.add_tokens(['[EMPTY_QUERY]', '[EMPTY_TITLE]'])\n",
    "model = model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path), config=config)\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "model.to(args.device)\n",
    "\n",
    "if args.model_type == 'hier':\n",
    "    for layer in model.bert.encoder.layer:\n",
    "        layer.hier.att.attention.load_state_dict(layer.attention.state_dict())\n",
    "        layer.hier.att.intermediate.load_state_dict(layer.intermediate.state_dict())\n",
    "        layer.hier.att.output.load_state_dict(layer.output.state_dict())\n",
    "\n",
    "\n",
    "logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "\n",
    "# Training\n",
    "if args.do_train:\n",
    "    # train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)\n",
    "    train_dataset = ConcatModelDataset(os.path.join(args.data_dir, \"session_train.txt\"), args.include_skipped,\n",
    "                               args.max_seq_length, tokenizer, args.output_mode, args.load_small, args.dataset,\n",
    "                                 args.history_num)\n",
    "    eval_dataset = ConcatModelDataset(os.path.join(args.data_dir, \"session_dev_small.txt\"), args.include_skipped, \n",
    "                                args.max_seq_length, tokenizer, args.output_mode, args.load_small, args.dataset,\n",
    "                                 args.history_num)\n",
    "    test_dataset = ConcatModelDataset(os.path.join(args.data_dir, \"session_test.txt\"), args.include_skipped, \n",
    "                                args.max_seq_length, tokenizer, args.output_mode, args.load_small, args.dataset,\n",
    "                                 args.history_num)\n",
    "    global_step, tr_loss = train(args, train_dataset, eval_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "#     if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "#         # Create output directory if needed\n",
    "#         if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "#             os.makedirs(args.output_dir)\n",
    "\n",
    "#         logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "#         # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "#         # They can then be reloaded using `from_pretrained()`\n",
    "#         model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#         model_to_save.save_pretrained(args.output_dir)\n",
    "#         tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "#         # Good practice: save your training arguments together with the trained model\n",
    "#         torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n",
    "\n",
    "#         # Load a trained model and vocabulary that you have fine-tuned\n",
    "#         model = model_class.from_pretrained(args.output_dir)\n",
    "#         tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "#         model.to(args.device)\n",
    "\n",
    "\n",
    "# Evaluation on test set\n",
    "results = {}\n",
    "if args.do_eval and args.local_rank in [-1, 0]:\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "    logger.info(\"Testing\")\n",
    "    model = model_class.from_pretrained(os.path.join(args.output_dir, 'checkpoint'))\n",
    "    model.to(args.device)\n",
    "    result, test_output = evaluate(args, test_dataset, model, \n",
    "                                   tokenizer, args.per_gpu_test_batch_size, prefix='test')\n",
    "    result = dict((k + '_{}'.format('test'), v) for k, v in result.items())\n",
    "    results.update(result)\n",
    "\n",
    "    output_eval_file = os.path.join(args.output_dir, \"test_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        for key in sorted(results.keys()):\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "\n",
    "    output_test_preds_file = os.path.join(args.output_dir, \"test_preds.txt\")\n",
    "    with open(output_test_preds_file, 'w') as writer:\n",
    "        json.dump(test_output, writer)\n",
    "\n",
    "    # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
