{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertTokenizer)\n",
    "from modeling import BertConcatForStatefulSearch\n",
    "\n",
    "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
    "\n",
    "from utils import (compute_metrics, convert_examples_to_features, output_modes, ConcatModelDataset)\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertConcatForStatefulSearch, BertTokenizer),\n",
    "}\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        \n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_dataset, eval_dataset, model, tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter(os.path.join(args.output_dir, 'logs'))\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, \n",
    "                                  batch_size=args.train_batch_size, num_workers=8)\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args.warmup_steps, t_total=t_total)\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                          output_device=args.local_rank,\n",
    "                                                          find_unused_parameters=True)\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "                   args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    best_eval_mrr = 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
    "    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            guids = batch['guid']\n",
    "            batch = {k: v.to(args.device) for k, v in batch.items() if k != 'guid'}\n",
    "            inputs = {'input_ids':      batch['input_ids'],\n",
    "                      'attention_mask': batch['input_mask'],\n",
    "                      'token_type_ids': batch['segment_ids'],\n",
    "                      'labels':         batch['ranker_label_ids']}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu parallel training\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                optimizer.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics                   \n",
    "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar('loss', (tr_loss - logging_loss)/args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    # Save model checkpoint if it outperforms previous models\n",
    "                    # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                    if args.local_rank == -1 and args.evaluate_during_training:\n",
    "                        results, eval_output = evaluate(args, eval_dataset, model, \n",
    "                                                        tokenizer, args.per_gpu_eval_batch_size)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar('eval_{}'.format(key), value, global_step)\n",
    "                    \n",
    "                    if results['mrr'] > best_eval_mrr:\n",
    "                        best_eval_mrr = results['mrr']\n",
    "                        output_dir = os.path.join(args.output_dir, 'checkpoint')\n",
    "                        if not os.path.exists(output_dir):\n",
    "                            os.makedirs(output_dir)\n",
    "                        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "                        model_to_save.save_pretrained(output_dir)\n",
    "                        torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "                        logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "                        \n",
    "                        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "                        with open(output_eval_file, \"w\") as writer:\n",
    "                            logger.info(\"***** Best eval results so far *****\")\n",
    "                            for key in sorted(results.keys()):\n",
    "                                logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "                                writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "                                \n",
    "                        output_eval_preds_file = os.path.join(args.output_dir, \"eval_preds.txt\")\n",
    "                        with open(output_eval_preds_file, 'w') as writer:\n",
    "                            json.dump(eval_output, writer)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, eval_dataset, model, tokenizer, batch_size, prefix=\"\"):\n",
    "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "    eval_task = args.task_name\n",
    "    eval_output_dir = args.output_dir\n",
    "\n",
    "    results = {}\n",
    "    # eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)\n",
    "\n",
    "    if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(eval_output_dir)\n",
    "\n",
    "    args.eval_batch_size = batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, \n",
    "                                 batch_size=args.eval_batch_size, num_workers=8)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    all_eval_guids = []\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        eval_guids = batch['guid']\n",
    "        all_eval_guids.extend(eval_guids)\n",
    "        # batch = tuple(t.to(args.device) for t in batch)\n",
    "        batch = {k: v.to(args.device) for k, v in batch.items() if k != 'guid'}\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch['input_ids'],\n",
    "                      'attention_mask': batch['input_mask'],\n",
    "                      'token_type_ids': batch['segment_ids'],\n",
    "                      'labels':         batch['ranker_label_ids']}\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "            eval_loss += tmp_eval_loss.mean().item()\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            out_label_ids = inputs['labels'].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    if args.output_mode == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif args.output_mode == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    elif args.output_mode == \"ranking\":\n",
    "        preds = softmax(preds, axis=1)\n",
    "        preds = np.squeeze(preds[:, 1])    \n",
    "\n",
    "    result, qrels, run = compute_metrics(eval_task, preds, out_label_ids, guids=all_eval_guids)\n",
    "    results.update(result)\n",
    "    eval_output = {'qrels': qrels,\n",
    "                  'run': run,\n",
    "                  'ranker_test_all_label_ids': out_label_ids.tolist(),\n",
    "                  'guids': all_eval_guids,\n",
    "                  'preds': preds.tolist()}\n",
    "\n",
    "    # output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n",
    "    # with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results {} *****\".format(prefix))\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "        # writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "\n",
    "    return results, eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    ## Required parameters\n",
    "    parser.add_argument(\"--data_dir\", default='/mnt/scratch/chenqu/aol/preprocessed/', type=str, required=False,\n",
    "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "    parser.add_argument(\"--model_type\", default='bert', type=str, required=False,\n",
    "                        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()))\n",
    "    parser.add_argument(\"--model_name_or_path\", default='/mnt/scratch/chenqu/huggingface/', type=str, required=False,\n",
    "                        help=\"Path to pre-trained model or shortcut name\")\n",
    "    parser.add_argument(\"--task_name\", default='stateful_search', type=str, required=False,\n",
    "                        help=\"The name of the task to train\")\n",
    "    parser.add_argument(\"--output_dir\", default='/mnt/scratch/chenqu/stateful_search/12/', type=str, required=False,\n",
    "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "\n",
    "    ## Other parameters\n",
    "    parser.add_argument(\"--config_name\", default=\"\", type=str,\n",
    "                        help=\"Pretrained config name or path if not the same as model_name\")\n",
    "    parser.add_argument(\"--tokenizer_name\", default=\"\", type=str,\n",
    "                        help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "    parser.add_argument(\"--cache_dir\", default=\"\", type=str,\n",
    "                        help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "    parser.add_argument(\"--max_seq_length\", default=128, type=int,\n",
    "                        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "                             \"than this will be truncated, sequences shorter will be padded.\")\n",
    "    parser.add_argument(\"--do_train\", default=True, type=str2bool,\n",
    "                        help=\"Whether to run training.\")\n",
    "    parser.add_argument(\"--do_eval\", default=True, type=str2bool,\n",
    "                        help=\"Whether to run eval on the dev set.\")\n",
    "    parser.add_argument(\"--evaluate_during_training\", default=True, type=str2bool,\n",
    "                        help=\"Run evaluation during training at each logging step.\")\n",
    "    parser.add_argument(\"--do_lower_case\", default=True, type=str2bool,\n",
    "                        help=\"Set this flag if you are using an uncased model.\")\n",
    "\n",
    "    parser.add_argument(\"--per_gpu_train_batch_size\", default=32, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for training.\")\n",
    "    parser.add_argument(\"--per_gpu_eval_batch_size\", default=32, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "    parser.add_argument(\"--per_gpu_test_batch_size\", default=4, type=int,\n",
    "                        help=\"Batch size per GPU/CPU for testing.\")\n",
    "    parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument(\"--learning_rate\", default=3e-5, type=float,\n",
    "                        help=\"The initial learning rate for Adam.\")\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                        help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                        help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
    "                        help=\"Max gradient norm.\")\n",
    "    parser.add_argument(\"--num_train_epochs\", default=3.0, type=float,\n",
    "                        help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
    "                        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
    "                        help=\"Linear warmup over warmup_steps.\")\n",
    "\n",
    "    parser.add_argument('--logging_steps', type=int, default=5,\n",
    "                        help=\"Log and save checkpoint every X updates steps.\")\n",
    "    parser.add_argument('--save_steps', type=int, default=500,\n",
    "                        help=\"Save checkpoint every X updates steps, this is disabled in our code\")\n",
    "    parser.add_argument(\"--eval_all_checkpoints\", default=False, type=str2bool,\n",
    "                        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\")\n",
    "    parser.add_argument(\"--no_cuda\", default=False, type=str2bool,\n",
    "                        help=\"Avoid using CUDA when available\")\n",
    "    parser.add_argument('--overwrite_output_dir', default=True, type=str2bool,\n",
    "                        help=\"Overwrite the content of the output directory\")\n",
    "    parser.add_argument('--overwrite_cache', action='store_true',\n",
    "                        help=\"Overwrite the cached training and evaluation sets\")\n",
    "    parser.add_argument('--seed', type=int, default=42,\n",
    "                        help=\"random seed for initialization\")\n",
    "\n",
    "    parser.add_argument('--fp16', default=False, type=str2bool,\n",
    "                        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "    parser.add_argument('--fp16_opt_level', type=str, default='O1',\n",
    "                        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                             \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
    "                        help=\"For distributed training: local_rank\")\n",
    "    parser.add_argument('--server_ip', type=str, default='', help=\"For distant debugging.\")\n",
    "    parser.add_argument('--server_port', type=str, default='', help=\"For distant debugging.\")\n",
    "    \n",
    "    # parameters we added\n",
    "    parser.add_argument(\"--include_skipped\", default=True, type=str2bool, required=False,\n",
    "                        help=\"whether to include the skipped doc from prev turn\")\n",
    "    parser.add_argument(\"--enable_turn_id_embeddings\", default=True, type=str2bool, required=False,\n",
    "                        help=\"whether to enable turn id embeddings\")\n",
    "    parser.add_argument(\"--enable_component_embeddings\", default=True, type=str2bool, required=False,\n",
    "                        help=\"whether to enable component embeddings\")\n",
    "    parser.add_argument(\"--load_small\", default=False, type=str2bool, required=False,\n",
    "                        help=\"whether to just a small portion of data during development\")\n",
    "    parser.add_argument(\"--dataset\", default='aol', type=str, required=False,\n",
    "                        help=\"aol or bing. For bing data, we do not use the first query in a session\")\n",
    "    parser.add_argument(\"--history_num\", default=2, type=int, required=False,\n",
    "                        help=\"number of history turns to concat\")\n",
    "    \n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n",
    "\n",
    "    # Setup distant debugging if needed\n",
    "    if args.server_ip and args.server_port:\n",
    "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
    "        import ptvsd\n",
    "        print(\"Waiting for debugger attach\")\n",
    "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
    "        ptvsd.wait_for_attach()\n",
    "\n",
    "    # Setup CUDA, GPU & distributed training\n",
    "    if args.local_rank == -1 or args.no_cuda:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "        args.n_gpu = torch.cuda.device_count()\n",
    "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        device = torch.device(\"cuda\", args.local_rank)\n",
    "        torch.distributed.init_process_group(backend='nccl')\n",
    "        args.n_gpu = 1\n",
    "    args.device = device\n",
    "\n",
    "    # Setup logging\n",
    "    logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                        datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                        level = logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n",
    "    logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "                    args.local_rank, device, args.n_gpu, bool(args.local_rank != -1), args.fp16)\n",
    "\n",
    "    # Set seed\n",
    "    set_seed(args)\n",
    "\n",
    "    args.task_name = args.task_name.lower()\n",
    "    # if args.task_name not in processors:\n",
    "    #     raise ValueError(\"Task not found: %s\" % (args.task_name))\n",
    "    # processor = processors[args.task_name]()\n",
    "    args.output_mode = output_modes[args.task_name]\n",
    "    label_list = [\"False\", \"True\"]\n",
    "    num_labels = len(label_list)\n",
    "\n",
    "    # Load pretrained model and tokenizer\n",
    "    if args.local_rank not in [-1, 0]:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "    args.model_type = args.model_type.lower()\n",
    "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
    "    config = config_class.from_pretrained(args.config_name if args.config_name else args.model_name_or_path, num_labels=num_labels, finetuning_task=args.task_name)\n",
    "    tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else args.model_name_or_path, do_lower_case=args.do_lower_case)\n",
    "    tokenizer.add_tokens(['[EMPTY_QUERY]', '[EMPTY_TITLE]'])\n",
    "    model = model_class.from_pretrained(args.model_name_or_path, from_tf=bool('.ckpt' in args.model_name_or_path), config=config)\n",
    "\n",
    "    if args.local_rank == 0:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
    "\n",
    "    model.to(args.device)\n",
    "    \n",
    "    logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "\n",
    "    # Training\n",
    "    if args.do_train:\n",
    "        # train_dataset = load_and_cache_examples(args, args.task_name, tokenizer, evaluate=False)\n",
    "        train_dataset = ConcatModelDataset(os.path.join(args.data_dir, \"session_train.txt\"), args.include_skipped,\n",
    "                                   args.max_seq_length, tokenizer, args.output_mode, args.load_small, args.dataset,\n",
    "                                     args.history_num)\n",
    "        eval_dataset = ConcatModelDataset(os.path.join(args.data_dir, \"session_dev.txt\"), args.include_skipped, \n",
    "                                    args.max_seq_length, tokenizer, args.output_mode, args.load_small, args.dataset,\n",
    "                                     args.history_num)\n",
    "        test_dataset = ConcatModelDataset(os.path.join(args.data_dir, \"session_test.txt\"), args.include_skipped, \n",
    "                                    args.max_seq_length, tokenizer, args.output_mode, args.load_small, args.dataset,\n",
    "                                     args.history_num)\n",
    "        global_step, tr_loss = train(args, train_dataset, eval_dataset, model, tokenizer)\n",
    "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
    "\n",
    "\n",
    "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "#     if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "#         # Create output directory if needed\n",
    "#         if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "#             os.makedirs(args.output_dir)\n",
    "\n",
    "#         logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "#         # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "#         # They can then be reloaded using `from_pretrained()`\n",
    "#         model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "#         model_to_save.save_pretrained(args.output_dir)\n",
    "#         tokenizer.save_pretrained(args.output_dir)\n",
    "\n",
    "#         # Good practice: save your training arguments together with the trained model\n",
    "#         torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n",
    "\n",
    "#         # Load a trained model and vocabulary that you have fine-tuned\n",
    "#         model = model_class.from_pretrained(args.output_dir)\n",
    "#         tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "#         model.to(args.device)\n",
    "\n",
    "\n",
    "    # Evaluation on test set\n",
    "    results = {}\n",
    "    if args.do_eval and args.local_rank in [-1, 0]:\n",
    "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
    "        logger.info(\"Testing\")\n",
    "        model = model_class.from_pretrained(os.path.join(args.output_dir, 'checkpoint'))\n",
    "        model.to(args.device)\n",
    "        result, test_output = evaluate(args, test_dataset, model, \n",
    "                                       tokenizer, args.per_gpu_test_batch_size, prefix='test')\n",
    "        result = dict((k + '_{}'.format('test'), v) for k, v in result.items())\n",
    "        results.update(result)\n",
    "        \n",
    "        output_eval_file = os.path.join(args.output_dir, \"test_results.txt\")\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            for key in sorted(results.keys()):\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(results[key])))\n",
    "                \n",
    "        output_test_preds_file = os.path.join(args.output_dir, \"test_preds.txt\")\n",
    "        with open(output_test_preds_file, 'w') as writer:\n",
    "            json.dump(test_output, writer)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/08/2019 16:15:15 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.modeling_utils -   loading configuration file /mnt/scratch/chenqu/huggingface/config.json\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.modeling_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"stateful_search\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/huggingface/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming '/mnt/scratch/chenqu/huggingface/' is a path or url to a directory containing tokenizer files.\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /mnt/scratch/chenqu/huggingface/added_tokens.json. We won't load it.\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /mnt/scratch/chenqu/huggingface/special_tokens_map.json. We won't load it.\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   Didn't find file /mnt/scratch/chenqu/huggingface/tokenizer_config.json. We won't load it.\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/huggingface/vocab.txt\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
      "09/08/2019 16:15:15 - INFO - pytorch_transformers.tokenization_utils -   loading file None\n",
      "09/08/2019 16:15:16 - INFO - pytorch_transformers.tokenization_utils -   Adding [EMPTY_QUERY] to the vocabulary\n",
      "09/08/2019 16:15:16 - INFO - pytorch_transformers.tokenization_utils -   Adding [EMPTY_TITLE] to the vocabulary\n",
      "09/08/2019 16:15:16 - INFO - pytorch_transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/huggingface/pytorch_model.bin\n",
      "09/08/2019 16:15:19 - INFO - pytorch_transformers.modeling_utils -   Weights of BertConcatForStatefulSearch not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "09/08/2019 16:15:19 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertConcatForStatefulSearch: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "09/08/2019 16:15:22 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/mnt/scratch/chenqu/aol/preprocessed/', dataset='aol', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, enable_component_embeddings=True, enable_turn_id_embeddings=True, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, history_num=2, include_skipped=True, learning_rate=3e-05, load_small=False, local_rank=-1, logging_steps=5, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='/mnt/scratch/chenqu/huggingface/', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='/mnt/scratch/chenqu/stateful_search/12/', output_mode='ranking', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_test_batch_size=4, per_gpu_train_batch_size=32, save_steps=500, seed=42, server_ip='', server_port='', task_name='stateful_search', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
      "09/08/2019 16:15:22 - INFO - utils -   processing aol data\n",
      "09/08/2019 16:15:24 - INFO - utils -   processing aol data\n",
      "09/08/2019 16:15:24 - INFO - utils -   processing aol data\n",
      "09/08/2019 16:15:26 - INFO - __main__ -   ***** Running training *****\n",
      "09/08/2019 16:15:26 - INFO - __main__ -     Num examples = 2834835\n",
      "09/08/2019 16:15:26 - INFO - __main__ -     Num Epochs = 3\n",
      "09/08/2019 16:15:26 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
      "09/08/2019 16:15:26 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "09/08/2019 16:15:26 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "09/08/2019 16:15:26 - INFO - __main__ -     Total optimization steps = 265767\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/88589 [00:00<?, ?it/s]\u001b[A/net/home/chenqu/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "\n",
      "Iteration:   0%|          | 1/88589 [00:04<106:23:10,  4.32s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/88589 [00:04<78:53:49,  3.21s/it] \u001b[A\n",
      "Iteration:   0%|          | 3/88589 [00:05<59:35:48,  2.42s/it]\u001b[A\n",
      "Iteration:   0%|          | 4/88589 [00:06<46:07:26,  1.87s/it]\u001b[A\n",
      "Iteration:   0%|          | 5/88589 [00:06<36:41:36,  1.49s/it]\u001b[A\n",
      "Iteration:   0%|          | 6/88589 [00:07<30:15:34,  1.23s/it]\u001b[A\n",
      "Iteration:   0%|          | 7/88589 [00:07<25:42:37,  1.04s/it]\u001b[A\n",
      "Iteration:   0%|          | 8/88589 [00:08<22:37:45,  1.09it/s]\u001b[A\n",
      "Iteration:   0%|          | 9/88589 [00:09<20:23:31,  1.21it/s]\u001b[A\n",
      "Iteration:   0%|          | 10/88589 [00:09<18:49:50,  1.31it/s]\u001b[A\n",
      "Iteration:   0%|          | 11/88589 [00:10<17:43:56,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 12/88589 [00:11<16:56:51,  1.45it/s]\u001b[A\n",
      "Iteration:   0%|          | 13/88589 [00:11<16:22:56,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 14/88589 [00:12<16:00:58,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 15/88589 [00:12<15:51:05,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 16/88589 [00:13<15:43:43,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 17/88589 [00:14<15:36:50,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 18/88589 [00:14<15:30:30,  1.59it/s]\u001b[A\n",
      "Iteration:   0%|          | 19/88589 [00:15<15:28:47,  1.59it/s]\u001b[A\n",
      "Iteration:   0%|          | 20/88589 [00:16<15:30:02,  1.59it/s]\u001b[A\n",
      "Iteration:   0%|          | 21/88589 [00:16<15:26:40,  1.59it/s]\u001b[A\n",
      "Iteration:   0%|          | 22/88589 [00:17<15:24:28,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 23/88589 [00:17<15:23:54,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 24/88589 [00:18<15:23:49,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 25/88589 [00:19<15:24:52,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 26/88589 [00:19<15:24:19,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 27/88589 [00:20<15:23:53,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 28/88589 [00:21<15:22:54,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 29/88589 [00:21<15:21:00,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 30/88589 [00:22<15:22:11,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 31/88589 [00:22<15:21:46,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 32/88589 [00:23<15:23:13,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 33/88589 [00:24<15:24:18,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 34/88589 [00:24<15:23:19,  1.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 35/88589 [00:25<15:22:06,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 36/88589 [00:26<15:22:20,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 37/88589 [00:26<15:21:40,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 38/88589 [00:27<15:22:08,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 39/88589 [00:27<15:23:50,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 40/88589 [00:28<15:23:17,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 41/88589 [00:29<15:23:35,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 42/88589 [00:29<15:23:10,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 43/88589 [00:30<15:23:50,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 44/88589 [00:31<15:23:58,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 45/88589 [00:31<15:24:03,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 46/88589 [00:32<15:23:14,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 47/88589 [00:32<15:23:44,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 48/88589 [00:33<15:23:45,  1.60it/s]\u001b[A\n",
      "Iteration:   0%|          | 49/88589 [00:34<15:33:06,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 50/88589 [00:34<15:39:23,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 51/88589 [00:35<15:42:16,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 52/88589 [00:36<15:46:14,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 53/88589 [00:36<15:46:57,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 54/88589 [00:37<15:48:52,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 55/88589 [00:38<15:50:49,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 56/88589 [00:38<15:41:05,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 57/88589 [00:39<15:45:09,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 58/88589 [00:39<15:48:03,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 59/88589 [00:40<15:50:16,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 60/88589 [00:41<15:52:27,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 61/88589 [00:41<15:55:38,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 62/88589 [00:42<15:56:28,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 63/88589 [00:43<15:58:17,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 64/88589 [00:43<15:57:29,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 65/88589 [00:44<16:00:15,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 66/88589 [00:45<16:00:36,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 67/88589 [00:45<15:59:40,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 68/88589 [00:46<15:59:43,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 69/88589 [00:47<15:58:21,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 70/88589 [00:47<15:56:53,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 71/88589 [00:48<15:57:31,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 72/88589 [00:49<15:57:29,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 73/88589 [00:49<15:59:21,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 74/88589 [00:50<15:59:24,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 75/88589 [00:51<15:55:15,  1.54it/s]\u001b[A\n",
      "Iteration:   0%|          | 76/88589 [00:51<15:48:59,  1.55it/s]\u001b[A\n",
      "Iteration:   0%|          | 77/88589 [00:52<15:33:57,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 78/88589 [00:52<15:33:10,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 79/88589 [00:53<15:35:11,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 80/88589 [00:54<15:35:31,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 81/88589 [00:54<15:37:50,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 82/88589 [00:55<15:37:12,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 83/88589 [00:56<15:35:57,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 84/88589 [00:56<15:35:41,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 85/88589 [00:57<15:36:35,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 86/88589 [00:57<15:35:37,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 87/88589 [00:58<15:36:04,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 88/88589 [00:59<15:35:57,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 89/88589 [00:59<15:33:45,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 90/88589 [01:00<15:34:58,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 91/88589 [01:01<15:35:42,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 92/88589 [01:01<15:35:48,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 93/88589 [01:02<15:37:06,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 94/88589 [01:03<15:36:27,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 95/88589 [01:03<15:36:59,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 96/88589 [01:04<15:37:38,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 97/88589 [01:04<15:36:37,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 98/88589 [01:05<15:36:20,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 99/88589 [01:06<15:36:08,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 100/88589 [01:06<15:36:49,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 101/88589 [01:07<15:35:43,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 102/88589 [01:08<15:34:30,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 103/88589 [01:08<15:35:13,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 104/88589 [01:09<15:35:24,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 105/88589 [01:10<15:36:15,  1.58it/s]\u001b[A\n",
      "Iteration:   0%|          | 106/88589 [01:10<15:37:07,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 107/88589 [01:11<15:37:18,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 108/88589 [01:11<15:40:08,  1.57it/s]\u001b[A\n",
      "Iteration:   0%|          | 109/88589 [01:12<15:48:13,  1.56it/s]\u001b[A\n",
      "Iteration:   0%|          | 110/88589 [01:13<16:01:50,  1.53it/s]\u001b[A\n",
      "Iteration:   0%|          | 111/88589 [01:13<16:16:15,  1.51it/s]\u001b[A\n",
      "Iteration:   0%|          | 112/88589 [01:14<16:26:31,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 113/88589 [01:15<16:33:26,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 114/88589 [01:16<16:39:54,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 115/88589 [01:16<16:45:19,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 116/88589 [01:17<16:48:12,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 117/88589 [01:18<16:49:37,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 118/88589 [01:18<16:50:16,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 119/88589 [01:19<16:52:10,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 120/88589 [01:20<16:49:26,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 121/88589 [01:20<16:47:40,  1.46it/s]\u001b[A\n",
      "Iteration:   0%|          | 122/88589 [01:21<16:44:25,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 123/88589 [01:22<16:39:37,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 124/88589 [01:22<16:35:55,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 125/88589 [01:23<16:33:32,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 126/88589 [01:24<16:31:32,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 127/88589 [01:24<16:30:14,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 128/88589 [01:25<16:29:04,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 129/88589 [01:26<16:28:06,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 130/88589 [01:26<16:27:47,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 131/88589 [01:27<16:27:26,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 132/88589 [01:28<16:27:06,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 133/88589 [01:28<16:23:34,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 134/88589 [01:29<16:24:18,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 135/88589 [01:30<16:27:00,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 136/88589 [01:30<16:30:29,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 137/88589 [01:31<16:31:00,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 138/88589 [01:32<16:28:37,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 139/88589 [01:32<16:26:39,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 140/88589 [01:33<16:26:30,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 141/88589 [01:34<16:27:10,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 142/88589 [01:34<16:25:17,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 143/88589 [01:35<16:24:07,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 144/88589 [01:36<16:23:37,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 145/88589 [01:36<16:22:16,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 146/88589 [01:37<16:23:43,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 147/88589 [01:38<16:23:05,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 148/88589 [01:38<16:22:49,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 149/88589 [01:39<16:21:33,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 150/88589 [01:40<16:23:22,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 151/88589 [01:40<16:24:36,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 152/88589 [01:41<16:25:30,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 153/88589 [01:42<16:26:02,  1.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 154/88589 [01:42<16:25:55,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 155/88589 [01:43<16:27:09,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 156/88589 [01:44<16:26:35,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 157/88589 [01:44<16:23:59,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 158/88589 [01:45<16:24:51,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 159/88589 [01:46<16:25:12,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 160/88589 [01:46<16:25:47,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 161/88589 [01:47<16:27:42,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 162/88589 [01:48<16:29:28,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 163/88589 [01:48<16:34:34,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 164/88589 [01:49<16:33:11,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 165/88589 [01:50<16:32:03,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 166/88589 [01:50<16:29:18,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 167/88589 [01:51<16:28:19,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 168/88589 [01:52<16:27:35,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 169/88589 [01:52<16:27:53,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 170/88589 [01:53<16:29:59,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 171/88589 [01:54<16:34:16,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 172/88589 [01:54<16:34:34,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 173/88589 [01:55<16:34:36,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 174/88589 [01:56<16:33:27,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 175/88589 [01:57<16:34:29,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 176/88589 [01:57<16:34:47,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 177/88589 [01:58<16:31:18,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 178/88589 [01:59<16:29:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 179/88589 [01:59<16:28:50,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 180/88589 [02:00<16:28:33,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 181/88589 [02:01<16:26:45,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 182/88589 [02:01<16:26:45,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 183/88589 [02:02<16:26:27,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 184/88589 [02:03<16:26:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 185/88589 [02:03<16:26:52,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 186/88589 [02:04<16:28:43,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 187/88589 [02:05<16:30:30,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 188/88589 [02:05<16:31:45,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 189/88589 [02:06<16:31:30,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 190/88589 [02:07<16:30:09,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 191/88589 [02:07<16:28:53,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 192/88589 [02:08<16:27:07,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 193/88589 [02:09<16:28:35,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 194/88589 [02:09<16:30:28,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 195/88589 [02:10<16:30:45,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 196/88589 [02:11<16:29:47,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 197/88589 [02:11<16:28:46,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 198/88589 [02:12<16:27:53,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 199/88589 [02:13<16:26:17,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 200/88589 [02:13<16:28:24,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 201/88589 [02:14<16:30:32,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 202/88589 [02:15<16:32:00,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 203/88589 [02:15<16:24:24,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 204/88589 [02:16<16:26:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 205/88589 [02:17<16:29:29,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 206/88589 [02:17<16:31:01,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 207/88589 [02:18<16:34:35,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 208/88589 [02:19<16:30:29,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 209/88589 [02:19<16:29:02,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 210/88589 [02:20<16:27:33,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 211/88589 [02:21<16:27:23,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 212/88589 [02:21<16:28:08,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 213/88589 [02:22<16:28:39,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 214/88589 [02:23<16:28:57,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 215/88589 [02:23<16:29:51,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 216/88589 [02:24<16:31:25,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 217/88589 [02:25<16:32:38,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 218/88589 [02:25<16:33:00,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 219/88589 [02:26<16:33:07,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 220/88589 [02:27<16:31:28,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 221/88589 [02:27<16:29:55,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 222/88589 [02:28<16:28:25,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 223/88589 [02:29<16:27:33,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 224/88589 [02:29<16:26:58,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 225/88589 [02:30<16:27:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 226/88589 [02:31<16:29:40,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 227/88589 [02:31<16:30:46,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 228/88589 [02:32<16:30:52,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 229/88589 [02:33<16:33:25,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 230/88589 [02:33<16:33:44,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 231/88589 [02:34<16:31:31,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 232/88589 [02:35<16:29:16,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 233/88589 [02:35<16:28:19,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 234/88589 [02:36<16:28:20,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 235/88589 [02:37<16:28:41,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 236/88589 [02:37<16:29:47,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 237/88589 [02:38<16:22:26,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 238/88589 [02:39<16:25:11,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 239/88589 [02:39<16:27:09,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 240/88589 [02:40<16:28:57,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 241/88589 [02:41<16:30:55,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 242/88589 [02:42<16:30:15,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 243/88589 [02:42<16:30:03,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 244/88589 [02:43<16:31:17,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 245/88589 [02:44<16:33:59,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 246/88589 [02:44<16:34:04,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 247/88589 [02:45<16:33:35,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 248/88589 [02:46<16:33:25,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 249/88589 [02:46<16:33:25,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 250/88589 [02:47<16:35:09,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 251/88589 [02:48<16:35:38,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 252/88589 [02:48<16:35:29,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 253/88589 [02:49<16:34:54,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 254/88589 [02:50<16:34:31,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 255/88589 [02:50<16:34:54,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 256/88589 [02:51<16:35:34,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 257/88589 [02:52<16:37:16,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 258/88589 [02:52<16:36:45,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 259/88589 [02:53<16:36:01,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 260/88589 [02:54<16:35:24,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 261/88589 [02:54<16:35:23,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 262/88589 [02:55<16:34:45,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 263/88589 [02:56<16:36:01,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 264/88589 [02:56<16:35:12,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 265/88589 [02:57<16:33:39,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 266/88589 [02:58<16:33:12,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 267/88589 [02:58<16:34:22,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 268/88589 [02:59<16:34:42,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 269/88589 [03:00<16:35:32,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 270/88589 [03:00<16:35:38,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 271/88589 [03:01<16:35:23,  1.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 272/88589 [03:02<16:32:55,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 273/88589 [03:02<16:31:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 274/88589 [03:03<16:29:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 275/88589 [03:04<16:30:43,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 276/88589 [03:04<16:32:01,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 277/88589 [03:05<16:33:31,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 278/88589 [03:06<16:34:18,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 279/88589 [03:06<16:33:59,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 280/88589 [03:07<16:34:13,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 281/88589 [03:08<16:34:37,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 282/88589 [03:09<16:33:43,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 283/88589 [03:09<16:33:54,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 284/88589 [03:10<16:33:30,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 285/88589 [03:11<16:33:39,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 286/88589 [03:11<16:33:03,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 287/88589 [03:12<16:32:49,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 288/88589 [03:13<16:34:10,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 289/88589 [03:13<16:32:50,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 290/88589 [03:14<16:32:42,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 291/88589 [03:15<16:33:00,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 292/88589 [03:15<16:33:07,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 293/88589 [03:16<16:31:26,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 294/88589 [03:17<16:22:30,  1.50it/s]\u001b[A\n",
      "Iteration:   0%|          | 295/88589 [03:17<16:24:49,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 296/88589 [03:18<16:27:35,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 297/88589 [03:19<16:28:09,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 298/88589 [03:19<16:29:24,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 299/88589 [03:20<16:30:04,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 300/88589 [03:21<16:30:56,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 301/88589 [03:21<16:31:31,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 302/88589 [03:22<16:31:30,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 303/88589 [03:23<16:31:55,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 304/88589 [03:23<16:32:09,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 305/88589 [03:24<16:32:24,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 306/88589 [03:25<16:34:12,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 307/88589 [03:25<16:35:01,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 308/88589 [03:26<16:34:35,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 309/88589 [03:27<16:35:08,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 310/88589 [03:27<16:36:19,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 311/88589 [03:28<16:35:58,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 312/88589 [03:29<16:34:55,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 313/88589 [03:29<16:31:42,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 314/88589 [03:30<16:30:26,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 315/88589 [03:31<16:29:17,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 316/88589 [03:31<16:30:10,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 317/88589 [03:32<16:30:17,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 318/88589 [03:33<16:32:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 319/88589 [03:33<16:34:10,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 320/88589 [03:34<16:35:15,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 321/88589 [03:35<16:36:24,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 322/88589 [03:36<16:37:26,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 323/88589 [03:36<16:36:26,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 324/88589 [03:37<16:36:39,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 325/88589 [03:38<16:36:28,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 326/88589 [03:38<16:36:02,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 327/88589 [03:39<16:33:28,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 328/88589 [03:40<16:33:33,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 329/88589 [03:40<16:33:52,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 330/88589 [03:41<16:33:26,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 331/88589 [03:42<16:33:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 332/88589 [03:42<16:32:46,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 333/88589 [03:43<16:33:38,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 334/88589 [03:44<16:35:18,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 335/88589 [03:44<16:36:27,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 336/88589 [03:45<16:37:56,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 337/88589 [03:46<16:36:52,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 338/88589 [03:46<16:36:13,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 339/88589 [03:47<16:38:20,  1.47it/s]\u001b[A\n",
      "Iteration:   0%|          | 340/88589 [03:48<16:36:34,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 341/88589 [03:48<16:35:01,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 342/88589 [03:49<16:34:13,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 343/88589 [03:50<16:33:16,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 344/88589 [03:50<16:32:58,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 345/88589 [03:51<16:33:46,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 346/88589 [03:52<16:34:49,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 347/88589 [03:52<16:36:09,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 348/88589 [03:53<16:35:18,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 349/88589 [03:54<16:35:44,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 350/88589 [03:54<16:35:00,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 351/88589 [03:55<16:34:18,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 352/88589 [03:56<16:34:23,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 353/88589 [03:56<16:33:09,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 354/88589 [03:57<16:32:52,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 355/88589 [03:58<16:33:49,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 356/88589 [03:58<16:32:46,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 357/88589 [03:59<16:32:07,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 358/88589 [04:00<16:33:13,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 359/88589 [04:01<16:33:39,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 360/88589 [04:01<16:32:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 361/88589 [04:02<16:32:23,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 362/88589 [04:03<16:32:48,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 363/88589 [04:03<16:32:18,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 364/88589 [04:04<16:32:25,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 365/88589 [04:05<16:33:52,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 366/88589 [04:05<16:33:56,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 367/88589 [04:06<16:34:40,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 368/88589 [04:07<16:35:23,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 369/88589 [04:07<16:35:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 370/88589 [04:08<16:34:46,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 371/88589 [04:09<16:34:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 372/88589 [04:09<16:31:55,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 373/88589 [04:10<16:29:46,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 374/88589 [04:11<16:28:07,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 375/88589 [04:11<16:27:06,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 376/88589 [04:12<16:24:49,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 377/88589 [04:13<16:25:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 378/88589 [04:13<16:27:28,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 379/88589 [04:14<16:28:28,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 380/88589 [04:15<16:28:44,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 381/88589 [04:15<16:29:50,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 382/88589 [04:16<16:31:41,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 383/88589 [04:17<16:32:03,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 384/88589 [04:17<16:33:08,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 385/88589 [04:18<16:35:03,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 386/88589 [04:19<16:35:40,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 387/88589 [04:19<16:35:15,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 388/88589 [04:20<16:33:56,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 389/88589 [04:21<16:33:42,  1.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 390/88589 [04:21<16:33:41,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 391/88589 [04:22<16:30:40,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 392/88589 [04:23<16:28:11,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 393/88589 [04:23<16:26:53,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 394/88589 [04:24<16:25:14,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 395/88589 [04:25<16:26:48,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 396/88589 [04:25<16:28:15,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 397/88589 [04:26<16:28:35,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 398/88589 [04:27<16:29:37,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 399/88589 [04:27<16:30:09,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 400/88589 [04:28<16:30:11,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 401/88589 [04:29<16:30:35,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 402/88589 [04:30<16:30:54,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 403/88589 [04:30<16:32:14,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 404/88589 [04:31<16:32:26,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 405/88589 [04:32<16:32:17,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 406/88589 [04:32<16:31:51,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 407/88589 [04:33<16:31:22,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 408/88589 [04:34<16:30:30,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 409/88589 [04:34<16:29:34,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 410/88589 [04:35<16:31:16,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 411/88589 [04:36<16:32:21,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 412/88589 [04:36<16:32:10,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 413/88589 [04:37<16:32:05,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 414/88589 [04:38<16:30:20,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 415/88589 [04:38<16:29:54,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 416/88589 [04:39<16:30:02,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 417/88589 [04:40<16:30:24,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 418/88589 [04:40<16:29:40,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 419/88589 [04:41<16:29:34,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 420/88589 [04:42<16:30:19,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 421/88589 [04:42<16:30:16,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 422/88589 [04:43<16:30:11,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 423/88589 [04:44<16:30:20,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 424/88589 [04:44<16:28:45,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 425/88589 [04:45<16:29:20,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 426/88589 [04:46<16:28:46,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 427/88589 [04:46<16:28:22,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 428/88589 [04:47<16:29:00,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 429/88589 [04:48<16:29:32,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 430/88589 [04:48<16:30:20,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 431/88589 [04:49<16:30:55,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 432/88589 [04:50<16:29:10,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 433/88589 [04:50<16:29:00,  1.49it/s]\u001b[A\n",
      "Iteration:   0%|          | 434/88589 [04:51<16:29:26,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 435/88589 [04:52<16:29:41,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 436/88589 [04:52<16:31:28,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 437/88589 [04:53<16:32:53,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 438/88589 [04:54<16:33:17,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 439/88589 [04:54<16:32:59,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 440/88589 [04:55<16:33:37,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 441/88589 [04:56<16:33:06,  1.48it/s]\u001b[A\n",
      "Iteration:   0%|          | 442/88589 [04:57<16:41:56,  1.47it/s]\u001b[A\n",
      "Iteration:   1%|          | 443/88589 [04:57<16:47:24,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 444/88589 [04:58<16:50:17,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 445/88589 [04:59<16:51:40,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 446/88589 [04:59<16:38:22,  1.47it/s]\u001b[A\n",
      "Iteration:   1%|          | 447/88589 [05:00<16:45:15,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 448/88589 [05:01<16:41:35,  1.47it/s]\u001b[A\n",
      "Iteration:   1%|          | 449/88589 [05:01<16:38:00,  1.47it/s]\u001b[A\n",
      "Iteration:   1%|          | 450/88589 [05:02<16:36:10,  1.47it/s]\u001b[A\n",
      "Iteration:   1%|          | 451/88589 [05:03<16:34:08,  1.48it/s]\u001b[A\n",
      "Iteration:   1%|          | 452/88589 [05:03<16:32:15,  1.48it/s]\u001b[A\n",
      "Iteration:   1%|          | 453/88589 [05:04<16:32:15,  1.48it/s]\u001b[A\n",
      "Iteration:   1%|          | 454/88589 [05:05<16:39:12,  1.47it/s]\u001b[A\n",
      "Iteration:   1%|          | 455/88589 [05:05<16:43:13,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 456/88589 [05:06<16:46:05,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 457/88589 [05:07<16:47:35,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 458/88589 [05:07<16:51:56,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 459/88589 [05:08<16:53:16,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 460/88589 [05:09<16:53:57,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 461/88589 [05:10<16:56:20,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 462/88589 [05:10<16:57:30,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 463/88589 [05:11<16:56:29,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 464/88589 [05:12<16:54:19,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 465/88589 [05:12<16:54:19,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 466/88589 [05:13<16:52:42,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 467/88589 [05:14<16:54:33,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 468/88589 [05:14<16:54:16,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 469/88589 [05:15<16:55:56,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 470/88589 [05:16<16:56:27,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 471/88589 [05:16<16:57:39,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 472/88589 [05:17<16:58:19,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 473/88589 [05:18<16:58:04,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 474/88589 [05:19<16:58:11,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 475/88589 [05:19<16:59:24,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 476/88589 [05:20<16:55:25,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 477/88589 [05:21<16:54:18,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 478/88589 [05:21<16:54:16,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 479/88589 [05:22<16:52:32,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 480/88589 [05:23<16:49:46,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 481/88589 [05:23<16:50:22,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 482/88589 [05:24<16:50:23,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 483/88589 [05:25<16:50:50,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 484/88589 [05:25<16:50:04,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 485/88589 [05:26<16:49:04,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 486/88589 [05:27<16:46:30,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 487/88589 [05:27<16:47:11,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 488/88589 [05:28<16:48:26,  1.46it/s]\u001b[A\n",
      "Iteration:   1%|          | 489/88589 [05:29<16:50:38,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 490/88589 [05:30<16:51:05,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 491/88589 [05:30<16:51:20,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 492/88589 [05:31<16:53:47,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 493/88589 [05:32<16:54:58,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 494/88589 [05:32<16:55:56,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 495/88589 [05:33<16:56:44,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 496/88589 [05:34<16:58:30,  1.44it/s]\u001b[A\n",
      "Iteration:   1%|          | 497/88589 [05:34<16:55:45,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 498/88589 [05:35<16:54:13,  1.45it/s]\u001b[A\n",
      "Iteration:   1%|          | 499/88589 [05:36<16:52:52,  1.45it/s]\u001b[A09/08/2019 16:21:03 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "09/08/2019 16:21:03 - INFO - __main__ -     Num examples = 440105\n",
      "09/08/2019 16:21:03 - INFO - __main__ -     Batch size = 32\n",
      "\n",
      "\n",
      "Evaluating:   0%|          | 0/13754 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 1/13754 [00:01<4:56:48,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 2/13754 [00:01<3:42:20,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 3/13754 [00:01<2:50:28,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 4/13754 [00:01<2:13:23,  1.72it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 5/13754 [00:02<1:47:46,  2.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 6/13754 [00:02<1:29:22,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 7/13754 [00:02<1:16:40,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 8/13754 [00:02<1:07:45,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 9/13754 [00:02<1:01:40,  3.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 10/13754 [00:03<57:34,  3.98it/s] \u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 11/13754 [00:03<54:45,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 12/13754 [00:03<52:57,  4.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 13/13754 [00:03<52:02,  4.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 14/13754 [00:04<51:18,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 15/13754 [00:04<50:56,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 16/13754 [00:04<50:39,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 17/13754 [00:04<50:35,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 18/13754 [00:04<50:33,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 19/13754 [00:05<50:31,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 20/13754 [00:05<50:29,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 21/13754 [00:05<50:35,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 22/13754 [00:05<50:48,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 23/13754 [00:06<50:46,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 24/13754 [00:06<50:48,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 25/13754 [00:06<50:48,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 26/13754 [00:06<50:41,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 27/13754 [00:06<50:38,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 28/13754 [00:07<50:40,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 29/13754 [00:07<50:40,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 30/13754 [00:07<50:43,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 31/13754 [00:07<50:44,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 32/13754 [00:08<50:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 33/13754 [00:08<50:40,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 34/13754 [00:08<50:46,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 35/13754 [00:08<50:45,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 36/13754 [00:08<50:40,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 37/13754 [00:09<50:38,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 38/13754 [00:09<50:33,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 39/13754 [00:09<50:32,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 40/13754 [00:09<50:30,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 41/13754 [00:09<50:30,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 42/13754 [00:10<50:34,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 43/13754 [00:10<50:34,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 44/13754 [00:10<50:36,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 45/13754 [00:10<50:37,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 46/13754 [00:11<50:38,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 47/13754 [00:11<50:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 48/13754 [00:11<50:39,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 49/13754 [00:11<50:37,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 50/13754 [00:11<50:37,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 51/13754 [00:12<50:37,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 52/13754 [00:12<50:34,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 53/13754 [00:12<50:33,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 54/13754 [00:12<50:34,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 55/13754 [00:13<50:35,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 56/13754 [00:13<50:37,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 57/13754 [00:13<50:39,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 58/13754 [00:13<50:42,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 59/13754 [00:13<50:50,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 60/13754 [00:14<50:55,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 61/13754 [00:14<50:53,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 62/13754 [00:14<50:59,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 63/13754 [00:14<51:07,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 64/13754 [00:15<51:09,  4.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 65/13754 [00:15<50:58,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 66/13754 [00:15<50:52,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 67/13754 [00:15<50:45,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0%|          | 68/13754 [00:16<50:41,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 69/13754 [00:16<50:38,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 70/13754 [00:16<50:35,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 71/13754 [00:16<50:32,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 72/13754 [00:16<50:30,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 73/13754 [00:17<50:30,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 74/13754 [00:17<50:29,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 75/13754 [00:17<50:30,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 76/13754 [00:17<50:30,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 77/13754 [00:17<50:28,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 78/13754 [00:18<50:25,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 79/13754 [00:18<50:25,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 80/13754 [00:18<50:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 81/13754 [00:18<50:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 82/13754 [00:19<50:25,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 83/13754 [00:19<50:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 84/13754 [00:19<50:24,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 85/13754 [00:19<50:22,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 86/13754 [00:19<50:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 87/13754 [00:20<50:26,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 88/13754 [00:20<50:27,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 89/13754 [00:20<50:28,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 90/13754 [00:20<50:28,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 91/13754 [00:21<50:27,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 92/13754 [00:21<50:37,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 93/13754 [00:21<50:36,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 94/13754 [00:21<50:36,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 95/13754 [00:21<50:34,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 96/13754 [00:22<50:29,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 97/13754 [00:22<50:27,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 98/13754 [00:22<50:24,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 99/13754 [00:22<50:25,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 100/13754 [00:23<50:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 101/13754 [00:23<50:24,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 102/13754 [00:23<50:26,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 103/13754 [00:23<50:27,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 104/13754 [00:23<50:25,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 105/13754 [00:24<50:25,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 106/13754 [00:24<50:37,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 107/13754 [00:24<50:34,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 108/13754 [00:24<50:32,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 109/13754 [00:25<50:28,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 110/13754 [00:25<50:23,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 111/13754 [00:25<50:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 112/13754 [00:25<50:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 113/13754 [00:25<50:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 114/13754 [00:26<50:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 115/13754 [00:26<50:18,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 116/13754 [00:26<50:17,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 117/13754 [00:26<50:17,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 118/13754 [00:27<50:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 119/13754 [00:27<50:23,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 120/13754 [00:27<50:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 121/13754 [00:27<50:25,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 122/13754 [00:27<50:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 123/13754 [00:28<50:19,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 124/13754 [00:28<50:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 125/13754 [00:28<50:20,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 126/13754 [00:28<50:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 127/13754 [00:29<50:23,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 128/13754 [00:29<50:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 129/13754 [00:29<50:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 130/13754 [00:29<50:23,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 131/13754 [00:29<50:19,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 132/13754 [00:30<50:15,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 133/13754 [00:30<50:16,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 134/13754 [00:30<50:12,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 135/13754 [00:30<50:12,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 136/13754 [00:31<50:14,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 137/13754 [00:31<50:11,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 138/13754 [00:31<50:11,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 139/13754 [00:31<50:13,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 140/13754 [00:31<50:11,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 141/13754 [00:32<50:10,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 142/13754 [00:32<50:07,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 143/13754 [00:32<50:09,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 144/13754 [00:32<50:07,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 145/13754 [00:33<50:06,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 146/13754 [00:33<50:07,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 147/13754 [00:33<50:08,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 148/13754 [00:33<50:15,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 149/13754 [00:33<50:13,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 150/13754 [00:34<50:09,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 151/13754 [00:34<50:09,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 152/13754 [00:34<50:08,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 153/13754 [00:34<50:08,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 154/13754 [00:35<50:19,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 155/13754 [00:35<50:18,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 156/13754 [00:35<50:17,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 157/13754 [00:35<50:16,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 158/13754 [00:35<50:10,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 159/13754 [00:36<50:10,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 160/13754 [00:36<50:08,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 161/13754 [00:36<50:09,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 162/13754 [00:36<50:09,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 163/13754 [00:37<50:09,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 164/13754 [00:37<50:05,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 165/13754 [00:37<50:02,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 166/13754 [00:37<50:02,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 167/13754 [00:37<50:04,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 168/13754 [00:38<50:04,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 169/13754 [00:38<50:04,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 170/13754 [00:38<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|          | 171/13754 [00:38<50:03,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 172/13754 [00:39<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 173/13754 [00:39<50:00,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 174/13754 [00:39<50:01,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 175/13754 [00:39<50:00,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 176/13754 [00:39<49:59,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 177/13754 [00:40<49:58,  4.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 178/13754 [00:40<50:00,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 179/13754 [00:40<50:03,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 180/13754 [00:40<50:03,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 181/13754 [00:41<50:05,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 182/13754 [00:41<50:13,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 183/13754 [00:41<50:12,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 184/13754 [00:41<50:10,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 185/13754 [00:41<50:08,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 186/13754 [00:42<50:05,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 187/13754 [00:42<50:04,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 188/13754 [00:42<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 189/13754 [00:42<50:01,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 190/13754 [00:43<50:01,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 191/13754 [00:43<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 192/13754 [00:43<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 193/13754 [00:43<50:01,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 194/13754 [00:43<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 195/13754 [00:44<50:02,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 196/13754 [00:44<50:03,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 197/13754 [00:44<50:04,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 198/13754 [00:44<50:04,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 199/13754 [00:45<50:04,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 200/13754 [00:45<50:02,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 201/13754 [00:45<50:00,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 202/13754 [00:45<49:59,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 203/13754 [00:45<49:58,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 204/13754 [00:46<49:58,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 205/13754 [00:46<49:58,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1%|▏         | 206/13754 [00:46<49:56,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 207/13754 [00:46<49:56,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 208/13754 [00:47<49:54,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 209/13754 [00:47<49:58,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 210/13754 [00:47<50:04,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 211/13754 [00:47<50:05,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 212/13754 [00:47<50:05,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 213/13754 [00:48<50:06,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 214/13754 [00:48<50:02,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 215/13754 [00:48<49:58,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 216/13754 [00:48<49:58,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 217/13754 [00:48<50:00,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 218/13754 [00:49<49:57,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 219/13754 [00:49<49:56,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 220/13754 [00:49<50:00,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 221/13754 [00:49<49:56,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 222/13754 [00:50<49:55,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 223/13754 [00:50<49:55,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 224/13754 [00:50<49:52,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 225/13754 [00:50<49:53,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 226/13754 [00:50<49:52,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 227/13754 [00:51<49:52,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 228/13754 [00:51<49:52,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 229/13754 [00:51<49:52,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 230/13754 [00:51<49:49,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 231/13754 [00:52<49:50,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 232/13754 [00:52<49:49,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 233/13754 [00:52<49:52,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 234/13754 [00:52<49:53,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 235/13754 [00:52<49:51,  4.52it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 236/13754 [00:53<49:50,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 237/13754 [00:53<49:51,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 238/13754 [00:53<49:51,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 239/13754 [00:53<49:51,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 240/13754 [00:54<49:51,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 241/13754 [00:54<49:51,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 242/13754 [00:54<49:50,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 243/13754 [00:54<49:50,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 244/13754 [00:54<49:50,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 245/13754 [00:55<49:48,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 246/13754 [00:55<49:47,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 247/13754 [00:55<49:47,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 248/13754 [00:55<49:49,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 249/13754 [00:56<49:47,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 250/13754 [00:56<49:48,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 251/13754 [00:56<49:49,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 252/13754 [00:56<49:48,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 253/13754 [00:56<49:47,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 254/13754 [00:57<49:45,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 255/13754 [00:57<49:46,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 256/13754 [00:57<49:44,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 257/13754 [00:57<49:43,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 258/13754 [00:58<49:46,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 259/13754 [00:58<49:52,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 260/13754 [00:58<49:54,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 261/13754 [00:58<49:55,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 262/13754 [00:58<49:55,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 263/13754 [00:59<49:53,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 264/13754 [00:59<50:03,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 265/13754 [00:59<50:05,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 266/13754 [00:59<50:03,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 267/13754 [01:00<50:02,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 268/13754 [01:00<49:58,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 269/13754 [01:00<49:55,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 270/13754 [01:00<49:53,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 271/13754 [01:00<49:53,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 272/13754 [01:01<49:53,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 273/13754 [01:01<49:54,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 274/13754 [01:01<49:51,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 275/13754 [01:01<49:50,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 276/13754 [01:02<49:49,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 277/13754 [01:02<49:50,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 278/13754 [01:02<49:50,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 279/13754 [01:02<49:47,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 280/13754 [01:02<49:47,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 281/13754 [01:03<49:49,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 282/13754 [01:03<49:47,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 283/13754 [01:03<49:48,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 284/13754 [01:03<49:46,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 285/13754 [01:04<49:43,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 286/13754 [01:04<49:44,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 287/13754 [01:04<49:44,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 288/13754 [01:04<49:45,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 289/13754 [01:04<49:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 290/13754 [01:05<49:47,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 291/13754 [01:05<49:50,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 292/13754 [01:05<49:51,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 293/13754 [01:05<49:48,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 294/13754 [01:06<49:45,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 295/13754 [01:06<49:55,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 296/13754 [01:06<50:04,  4.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 297/13754 [01:06<49:58,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 298/13754 [01:06<49:53,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 299/13754 [01:07<49:55,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 300/13754 [01:07<49:55,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 301/13754 [01:07<49:54,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 302/13754 [01:07<49:48,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 303/13754 [01:08<49:43,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 304/13754 [01:08<49:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 305/13754 [01:08<49:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 306/13754 [01:08<49:41,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 307/13754 [01:08<49:42,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 308/13754 [01:09<49:38,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 309/13754 [01:09<49:37,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 310/13754 [01:09<49:37,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 311/13754 [01:09<49:35,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 312/13754 [01:10<49:37,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 313/13754 [01:10<49:35,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 314/13754 [01:10<49:44,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 315/13754 [01:10<49:40,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 316/13754 [01:10<49:49,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 317/13754 [01:11<49:47,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 318/13754 [01:11<49:43,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 319/13754 [01:11<49:43,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 320/13754 [01:11<49:40,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 321/13754 [01:12<49:36,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 322/13754 [01:12<49:36,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 323/13754 [01:12<49:34,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 324/13754 [01:12<49:34,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 325/13754 [01:12<49:34,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 326/13754 [01:13<49:33,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 327/13754 [01:13<49:31,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 328/13754 [01:13<49:31,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 329/13754 [01:13<49:30,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 330/13754 [01:14<49:30,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 331/13754 [01:14<49:30,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 332/13754 [01:14<49:30,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 333/13754 [01:14<49:29,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 334/13754 [01:14<49:27,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 335/13754 [01:15<49:29,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 336/13754 [01:15<49:29,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 337/13754 [01:15<49:27,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 338/13754 [01:15<49:26,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 339/13754 [01:16<49:26,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 340/13754 [01:16<49:27,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 341/13754 [01:16<49:28,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 342/13754 [01:16<49:28,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2%|▏         | 343/13754 [01:16<49:27,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 344/13754 [01:17<49:25,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 345/13754 [01:17<49:27,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 346/13754 [01:17<49:24,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 347/13754 [01:17<49:24,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 348/13754 [01:18<49:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 349/13754 [01:18<49:26,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 350/13754 [01:18<49:39,  4.50it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   3%|▎         | 351/13754 [01:18<49:38,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 352/13754 [01:18<49:39,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 353/13754 [01:19<49:35,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 354/13754 [01:19<49:33,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 355/13754 [01:19<49:31,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 356/13754 [01:19<49:30,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 357/13754 [01:20<49:27,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 358/13754 [01:20<49:26,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 359/13754 [01:20<49:25,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 360/13754 [01:20<49:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 361/13754 [01:20<49:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 362/13754 [01:21<49:23,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 363/13754 [01:21<49:24,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 364/13754 [01:21<49:25,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 365/13754 [01:21<49:24,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 366/13754 [01:22<49:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 367/13754 [01:22<49:21,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 368/13754 [01:22<49:21,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 369/13754 [01:22<49:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 370/13754 [01:22<49:21,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 371/13754 [01:23<49:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 372/13754 [01:23<49:21,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 373/13754 [01:23<49:22,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 374/13754 [01:23<49:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 375/13754 [01:24<49:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 376/13754 [01:24<49:17,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 377/13754 [01:24<49:17,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 378/13754 [01:24<49:16,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 379/13754 [01:24<49:16,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 380/13754 [01:25<49:17,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 381/13754 [01:25<49:18,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 382/13754 [01:25<49:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 383/13754 [01:25<49:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 384/13754 [01:26<49:21,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 385/13754 [01:26<49:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 386/13754 [01:26<49:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 387/13754 [01:26<49:20,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 388/13754 [01:26<49:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 389/13754 [01:27<49:19,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 390/13754 [01:27<49:18,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 391/13754 [01:27<49:18,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 392/13754 [01:27<49:26,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 393/13754 [01:27<49:27,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 394/13754 [01:28<49:25,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 395/13754 [01:28<49:25,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 396/13754 [01:28<49:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 397/13754 [01:28<49:19,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 398/13754 [01:29<49:18,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 399/13754 [01:29<49:16,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 400/13754 [01:29<49:13,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 401/13754 [01:29<49:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 402/13754 [01:29<49:24,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 403/13754 [01:30<49:32,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 404/13754 [01:30<49:29,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 405/13754 [01:30<49:28,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 406/13754 [01:30<49:27,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 407/13754 [01:31<49:22,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 408/13754 [01:31<49:19,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 409/13754 [01:31<49:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 410/13754 [01:31<49:21,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 411/13754 [01:31<49:19,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 412/13754 [01:32<49:19,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 413/13754 [01:32<49:16,  4.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3%|▎         | 414/13754 [01:32<49:15,  4.51it/s]\u001b[A\u001b[AException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8e20628620>\n",
      "Traceback (most recent call last):\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/net/home/chenqu/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-5ce18155ad7d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m                                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                                      args.history_num)\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" global_step = %s, average loss = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7b50f859e7f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, eval_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_during_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                         results, eval_output = evaluate(args, eval_dataset, model, \n\u001b[0;32m--> 102\u001b[0;31m                                                         tokenizer, args.per_gpu_eval_batch_size)\n\u001b[0m\u001b[1;32m    103\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                             \u001b[0mtb_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b87064394b50>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(args, eval_dataset, model, tokenizer, batch_size, prefix)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mtmp_eval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0meval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_eval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnb_eval_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
